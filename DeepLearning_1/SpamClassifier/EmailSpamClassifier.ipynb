{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1> Email Classifier </h1> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the spam and valid emails are stored in 2 folders called \"easy_ham\" and \"spam\"\n",
    "#we want to read all the files in these 2 folders and pu the filenames into a list of spam and not spam\n",
    "ham_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"easy_ham\"))) if len(filename) > 20]\n",
    "spam_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"spam\"))) if len(filename) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "source": [
    "To parse emails we will use the email library of Python:\n",
    "\n",
    "How the email library works for parsing:\n",
    "\n",
    "The parser takes a serialized version of the email message(a stream of bytes) and converts it to a tree of EmailMessage objects.  The generator takes an EmailMessage and turns it back into a serialized byte stream.\n",
    "\n",
    "There are 2 parser interfaces available, the Parser API and FeedParser API. The Parser API is most useful when you have the entire text of the message in memory or if the entire message lives in a file on the file system. FeedParser API is useful when you are reading the message from a stream which might block your waiting(reading from a url itself)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all the parsed ham messages\n",
    "ham_path = os.path.join(os.getcwd(),\"easy_ham\")\n",
    "spam_path = os.path.join(os.getcwd(),\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = list()\n",
    "for filename in ham_filenames:\n",
    "    with open(os.path.join(ham_path,filename),'rb') as f:\n",
    "        ham_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = list()\n",
    "for filename in spam_filenames:\n",
    "    with open(os.path.join(spam_path,filename),'rb') as f:\n",
    "        spam_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n\n\n  | I can't reproduce this error.\n\nFor me it is very repeatable... (like every time, without fail).\n\nThis is the debug log of the pick happening ...\n\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n18:19:04 Ftoc_PickMsgs {{1 hit}}\n18:19:04 Marking 1 hits\n18:19:04 tkerror: syntax error in expression \"int ...\n\nNote, if I run the pick command by hand ...\n\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n1 hit\n\nThat's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\nusing is ...\n\ndelta$ pick -version\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n\nAnd the relevant part of my .mh_profile ...\n\ndelta$ mhparam pick\n-seq sel -list\n\n\nSince the pick command works, the sequence (actually, both of them, the\none that's explicit on the command line, from the search popup, and the\none that comes from .mh_profile) do get created.\n\nkre\n\nps: this is still using the version of the code form a day ago, I haven't\nbeen able to reach the cvs repository today (local routing issue I think).\n\n\n\n_______________________________________________\nExmh-workers mailing list\nExmh-workers@redhat.com\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\n"
     ]
    }
   ],
   "source": [
    "print(ham_messages[0].get_content().strip())"
   ]
  },
  {
   "source": [
    "Emails can have different parts to it, with images, attachments. And these attachments can have emails in them. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email,str):\n",
    "        return email\n",
    "    #get_payload() returns a list if the email is multipart and .is_multipart() = True\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload,list):\n",
    "        result = \"multipart({})\".format(', '.join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "        return result\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_counts_ham = structures_counter(ham_messages)\n",
    "structure_counts_spam = structures_counter(spam_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 2453),\n",
       " ('multipart(text/plain, application/pgp-signature)', 72),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "structure_counts_ham.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 221),\n",
       " ('text/html', 181),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 19),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "structure_counts_spam.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = list()\n",
    "temp = [[type_list.append(i) for i in structures] for structures in [structure_counts_ham, structure_counts_spam]]\n",
    "ham_type_counts = [structure_counts_ham[i] for i in set(type_list)]\n",
    "spam_type_counts = [structure_counts_spam[i] for i in set(type_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           Email Type  Ham Count  Spam Count\n",
       "0                    multipart(text/plain, video/mng)          1           0\n",
       "1                    multipart(text/plain, text/html)          8          45\n",
       "2                               multipart/alternative          0           1\n",
       "3      multipart(text/html, application/octet-stream)          0           2\n",
       "4        multipart(text/plain, multipart(text/plain))          1           0\n",
       "5                    multipart(text/html, text/plain)          0           1\n",
       "6    multipart(text/plain, application/x-java-applet)          1           0\n",
       "7                     multipart(multipart(text/html))          0           5\n",
       "8                   multipart(text/plain, text/plain)          4           0\n",
       "9   multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "10   multipart(text/plain, application/pgp-signature)         72           0\n",
       "11                               multipart(text/html)          0          19\n",
       "12                  multipart(text/plain, image/jpeg)          0           3\n",
       "13                                         text/plain       2453         221\n",
       "14  multipart(text/plain, application/x-pkcs7-sign...          1           0\n",
       "15  multipart(multipart(text/plain, text/html), im...          0           1\n",
       "16                                          text/html          0         181\n",
       "17                              multipart(text/plain)          3          19\n",
       "18    multipart(text/plain, application/octet-stream)          2           1\n",
       "19  multipart(text/plain, application/ms-tnef, tex...          1           0\n",
       "20               multipart(text/plain, text/enriched)          1           0\n",
       "21  multipart(multipart(text/plain, text/plain, te...          1           0\n",
       "22  multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "23  multipart(multipart(text/html), application/oc...          0           1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Email Type</th>\n      <th>Ham Count</th>\n      <th>Spam Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>multipart(text/plain, video/mng)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>multipart(text/plain, text/html)</td>\n      <td>8</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>multipart/alternative</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>multipart(text/html, application/octet-stream)</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multipart(text/plain, multipart(text/plain))</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>multipart(text/html, text/plain)</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>multipart(text/plain, application/x-java-applet)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>multipart(multipart(text/html))</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>multipart(text/plain, text/plain)</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>multipart(text/plain, application/pgp-signature)</td>\n      <td>72</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>multipart(text/html)</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>multipart(text/plain, image/jpeg)</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>text/plain</td>\n      <td>2453</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>multipart(text/plain, application/x-pkcs7-sign...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>multipart(multipart(text/plain, text/html), im...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>text/html</td>\n      <td>0</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>multipart(text/plain)</td>\n      <td>3</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>multipart(text/plain, application/octet-stream)</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>multipart(text/plain, application/ms-tnef, tex...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>multipart(text/plain, text/enriched)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>multipart(multipart(text/plain, text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>multipart(multipart(text/html), application/oc...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "type_counts_df = pd.DataFrame({'Email Type':list(set(type_list)), 'Ham Count':ham_type_counts, 'Spam Count':spam_type_counts})\n",
    "type_counts_df"
   ]
  },
  {
   "source": [
    "Most valid(ham) emails are text/plain and contain a PGP(Pretty Good Privacy) signature, while Spam emails have a higher amount of HTML messages. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of type of each email \n",
    "ham_email_type = [get_email_structure(email) for email in ham_messages]\n",
    "spam_email_type = [get_email_structure(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindEmailSender(email):\n",
    "    try:\n",
    "        return dict(email.items())['From']\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of senders of each email\n",
    "ham_email_senders = [FindEmailSender(email) for email in ham_messages]\n",
    "spam_email_senders = [FindEmailSender(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the dataset to create a complete dataset for splitting into train and test sets\n",
    "import numpy as np\n",
    "X = np.array(ham_messages + spam_messages, dtype = object)\n",
    "y = np.array([0] * len(ham_messages) + [1]*len(spam_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning html in emails into tags we want\n",
    "#turn head tags into ''\n",
    "#turn anchor tags into hyper links\n",
    "#turn all html tags into ''\n",
    "import re\n",
    "from html import unescape\n",
    "def html_to_text(html):\n",
    "    text = re.sub(r'<head.*?>.*?</head>','',html,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<a.*?>.*?</a>',' HYPERLINK ',text,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<.*?>','',text,flags=re.M|re.I|re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+','\\n',text,flags = re.M|re.I|re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_html = [i for i in range(len(X_train)) if get_email_structure(X_train[i]) == 'text/html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n HYPERLINK\\nCopyright 2002 - All rights reservedIf you would no longer like us\\nto contact you or feel that you havereceived this email in error,\\nplease  HYPERLINK .'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "html_to_text(X_train[idx_html[5]].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[41, 805, 942, 1131, 1219, 2033, 2134, 2266]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#check if any EmailMessage objects have more tha one text/html type occuring\n",
    "html_check = list()\n",
    "for j in range(len(X_train)):\n",
    "    i = 0\n",
    "    for part in X_train[j].walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            i += 1\n",
    "        if i == 2:\n",
    "            html_check.append(j)\n",
    "    \n",
    "html_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for sub_email in email.walk():\n",
    "        content_type = sub_email.get_content_type()\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text_multipart(email):\n",
    "    html = None\n",
    "    #the first sub_email that is traversed is the main parent email itself. the following will be the children\n",
    "    for sub_email in email.walk():\n",
    "        content_type = sub_email.get_content_type()\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            #if the parent mail is multipart, use this route\n",
    "            content_type = email.get_content_type()\n",
    "            if re.fullmatch(r'multipart/[a-zA-Z]+',content_type) != None:\n",
    "                textlist = list()\n",
    "                for sub_email_1 in email.get_payload():\n",
    "                    if sub_email_1.get_content_type() == 'text/plain':\n",
    "                        textlist.append(sub_email_1.get_content())\n",
    "                    elif sub_email_1.get_content_type() == 'text/html':\n",
    "                        textlist.append(html_to_text(sub_email_1.get_content()))\n",
    "                    else:\n",
    "                        continue\n",
    "                if (len(textlist) > 0):\n",
    "                    return ' '.join(textlist)\n",
    "            else:\n",
    "                continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts emails in the body to \"EMAIL\"\n",
    "import re\n",
    "def convert_email_tags(email_text):\n",
    "    return re.sub(r'([a-zA-Z0-9\\._-]+@[a-zA-Z0-9\\._-]+\\.[a-zA-Z0-9\\._-]+)',' EMAIL ',email_text,flags = re.I|re.S|re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(email_text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(email_text.strip())\n",
    "    return [i for i in words if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the words to get the root of words\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemmer(email_word_list):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(w) for w in email_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "class EmailToWord(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,lower_case = True, remove_email = True, remove_punctuation = True, remove_urls = True, stemming = True, remove_stopwords = True, remove_numbers = True):\n",
    "         self.lower_case =lower_case\n",
    "         self.remove_email = remove_email\n",
    "         self.remove_punctuation = remove_punctuation\n",
    "         self.remove_urls = remove_urls\n",
    "         self.stemming = stemming\n",
    "         self.remove_stopwords = remove_stopwords\n",
    "         self.remove_numbers = remove_numbers\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text_multipart(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.remove_urls:\n",
    "                url_extractor = urlextract.URLExtract()\n",
    "                urls = url_extractor.find_urls(text)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url,' URL ')\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'[^a-zA-Z0-9_]',' ', text, flags = re.M|re.S|re.I)\n",
    "            if self.remove_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', ' NUMBER ', text, flags = re.I|re.S|re.M)\n",
    "            if self.remove_email:\n",
    "                text = convert_email_tags(text)\n",
    "            if self.remove_stopwords:\n",
    "                #words without stemming\n",
    "                word_list = remove_stopwords(text)\n",
    "            if self.stemming:\n",
    "                stemmed_list = stemmer(word_list)\n",
    "            X_transformed.append(stemmed_list)\n",
    "        return X_transformed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "from collections import Counter\n",
    "class CountWords(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        #create a word vector\n",
    "        X_wordcounts = []\n",
    "        for email_word_list in X:\n",
    "            X_wordcounts.append(Counter(email_word_list))\n",
    "        return X_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailtowords = EmailToWord()\n",
    "test = emailtowords.fit_transform(X_train[:100])\n",
    "countwords = CountWords()\n",
    "countres = countwords.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Counter({'creator': 1,\n",
       "          'didnt': 1,\n",
       "          'say': 1,\n",
       "          'could': 1,\n",
       "          'without': 2,\n",
       "          'pay': 3,\n",
       "          'theft': 1,\n",
       "          'simpl': 1,\n",
       "          'hell': 1,\n",
       "          'even': 1,\n",
       "          'major': 1,\n",
       "          'holi': 1,\n",
       "          'book': 1,\n",
       "          'wow': 1,\n",
       "          'got': 1,\n",
       "          'great': 1,\n",
       "          'idea': 1,\n",
       "          'hire': 1,\n",
       "          'skywrit': 1,\n",
       "          'write': 1,\n",
       "          'look': 2,\n",
       "          'lock': 1,\n",
       "          'everybodi': 1,\n",
       "          'fail': 1,\n",
       "          'jesu': 1,\n",
       "          'side': 1,\n",
       "          'url': 1}),\n",
       " Counter({'date': 2,\n",
       "          'tue': 1,\n",
       "          'number': 10,\n",
       "          'aug': 1,\n",
       "          'brent': 1,\n",
       "          'welch': 2,\n",
       "          'panasa': 2,\n",
       "          'com': 3,\n",
       "          'messag': 1,\n",
       "          'id': 1,\n",
       "          'vaa': 1,\n",
       "          'blackcomb': 1,\n",
       "          'allow': 1,\n",
       "          'assum': 1,\n",
       "          'higher': 1,\n",
       "          'realli': 3,\n",
       "          'could': 1,\n",
       "          'add': 1,\n",
       "          'selecttypein': 1,\n",
       "          'procedur': 1,\n",
       "          'ye': 1,\n",
       "          'look': 3,\n",
       "          'fix': 1,\n",
       "          'code': 1,\n",
       "          'quit': 1,\n",
       "          'gener': 1,\n",
       "          'almost': 1,\n",
       "          'understand': 1,\n",
       "          'anyth': 1,\n",
       "          'mean': 1,\n",
       "          'think': 1,\n",
       "          'corrupt': 1,\n",
       "          'knowlwedg': 1,\n",
       "          'semant': 1,\n",
       "          'fetch': 1,\n",
       "          'would': 2,\n",
       "          'best': 1,\n",
       "          'thing': 1,\n",
       "          'ran': 1,\n",
       "          'time': 2,\n",
       "          'last': 1,\n",
       "          'night': 1,\n",
       "          'better': 1,\n",
       "          'place': 1,\n",
       "          'similar': 1,\n",
       "          'check': 1,\n",
       "          'gone': 1,\n",
       "          'directli': 1,\n",
       "          'regexp': 1,\n",
       "          'latest': 1,\n",
       "          'tcl': 1,\n",
       "          'chang': 1,\n",
       "          'sure': 1,\n",
       "          'today': 1,\n",
       "          'keep': 1,\n",
       "          'kre': 1,\n",
       "          '_______________________________________________': 1,\n",
       "          'exmh': 2,\n",
       "          'worker': 2,\n",
       "          'mail': 1,\n",
       "          'list': 1,\n",
       "          'redhat': 1,\n",
       "          'url': 1}),\n",
       " Counter({'week': 1,\n",
       "          'sydney': 1,\n",
       "          'bare': 1,\n",
       "          'park': 1,\n",
       "          'join': 1,\n",
       "          'live': 1,\n",
       "          'teen': 1,\n",
       "          'chat': 1,\n",
       "          'watch': 2,\n",
       "          'sandi': 1,\n",
       "          'strip': 1,\n",
       "          'nake': 1,\n",
       "          'dorm': 1,\n",
       "          'best': 1,\n",
       "          'see': 1,\n",
       "          'hyperlink': 2,\n",
       "          'miss': 1,\n",
       "          'awe': 1,\n",
       "          'stacey': 1,\n",
       "          'suck': 1,\n",
       "          'start': 1,\n",
       "          'ken': 1,\n",
       "          'bonu': 1,\n",
       "          'pam': 1,\n",
       "          'tommi': 1,\n",
       "          'uncut': 1,\n",
       "          'penthous': 1,\n",
       "          'forum': 1,\n",
       "          'stori': 1,\n",
       "          'jenna': 1,\n",
       "          'jamieson': 1,\n",
       "          'jennamaxx': 1,\n",
       "          'get': 1}),\n",
       " Counter({'saturday': 1,\n",
       "          'number': 22,\n",
       "          'septemb': 1,\n",
       "          'pm': 1,\n",
       "          'struggl': 1,\n",
       "          'free': 3,\n",
       "          'say': 2,\n",
       "          'although': 1,\n",
       "          'like': 4,\n",
       "          'total': 1,\n",
       "          'shock': 1,\n",
       "          'nine': 1,\n",
       "          'employ': 1,\n",
       "          'websit': 1,\n",
       "          'design': 1,\n",
       "          'truth': 1,\n",
       "          'webform': 1,\n",
       "          'accept': 2,\n",
       "          'u': 1,\n",
       "          'countri': 1,\n",
       "          'incred': 1,\n",
       "          'true': 1,\n",
       "          'web': 1,\n",
       "          'form': 2,\n",
       "          'also': 2,\n",
       "          'multipl': 1,\n",
       "          'even': 3,\n",
       "          'telephon': 1,\n",
       "          'partit': 1,\n",
       "          'manag': 1,\n",
       "          'step': 1,\n",
       "          'done': 1,\n",
       "          'without': 1,\n",
       "          'sell': 2,\n",
       "          'exclus': 1,\n",
       "          'right': 1,\n",
       "          'wallet': 1,\n",
       "          'world': 1,\n",
       "          'second': 1,\n",
       "          'richest': 1,\n",
       "          'corpor': 1,\n",
       "          'assum': 1,\n",
       "          'cisco': 1,\n",
       "          'still': 1,\n",
       "          'vendor': 1,\n",
       "          'lock': 1,\n",
       "          'busi': 1,\n",
       "          'small': 2,\n",
       "          'transact': 1,\n",
       "          'fee': 1,\n",
       "          'tith': 1,\n",
       "          'think': 2,\n",
       "          'peopl': 1,\n",
       "          'place': 1,\n",
       "          'would': 1,\n",
       "          'get': 3,\n",
       "          'unsolicit': 1,\n",
       "          'mail': 2,\n",
       "          'invent': 1,\n",
       "          'though': 1,\n",
       "          'perhap': 1,\n",
       "          'order': 1,\n",
       "          'enron': 1,\n",
       "          'mug': 1,\n",
       "          'king': 1,\n",
       "          'hell': 1,\n",
       "          'p': 2,\n",
       "          'met': 1,\n",
       "          'whatev': 2,\n",
       "          'commerci': 1,\n",
       "          'forum': 1,\n",
       "          'rock': 1,\n",
       "          'yesterday': 1,\n",
       "          'took': 1,\n",
       "          'greg': 1,\n",
       "          'extra': 1,\n",
       "          'serotonin': 1,\n",
       "          'lit': 1,\n",
       "          'made': 1,\n",
       "          'success': 1,\n",
       "          'go': 1,\n",
       "          'person': 1,\n",
       "          'address': 1,\n",
       "          'palett': 1,\n",
       "          'could': 1,\n",
       "          'occupi': 1,\n",
       "          'rent': 1,\n",
       "          'move': 1,\n",
       "          'repli': 1,\n",
       "          'whitepap': 1,\n",
       "          'site': 1,\n",
       "          'call': 1,\n",
       "          'real': 1,\n",
       "          'deal': 1,\n",
       "          'okay': 1,\n",
       "          'let': 1,\n",
       "          'factorytown': 1,\n",
       "          'guangzhou': 1,\n",
       "          'batteri': 1,\n",
       "          'acid': 1,\n",
       "          'supervisor': 1,\n",
       "          'multin': 1,\n",
       "          'sometim': 1,\n",
       "          'buy': 1,\n",
       "          'b': 1,\n",
       "          'e': 1,\n",
       "          'stori': 1,\n",
       "          'written': 1,\n",
       "          'way': 1,\n",
       "          'today': 1,\n",
       "          'lb': 1,\n",
       "          'tall': 1,\n",
       "          'mophead': 1,\n",
       "          'pearlec': 1,\n",
       "          'teeth': 1,\n",
       "          'excel': 1,\n",
       "          'sex': 1,\n",
       "          'link': 2,\n",
       "          'featur': 2,\n",
       "          'use': 3,\n",
       "          'solari': 1,\n",
       "          'nntp': 1,\n",
       "          'client': 1,\n",
       "          'got': 1,\n",
       "          'mere': 1,\n",
       "          'read': 1,\n",
       "          'base': 1,\n",
       "          'messag': 1,\n",
       "          'alphabet': 1,\n",
       "          'letter': 1,\n",
       "          'word': 1,\n",
       "          'come': 1,\n",
       "          'bibl': 1,\n",
       "          'calculu': 1,\n",
       "          'thank': 1,\n",
       "          'class': 1,\n",
       "          'catamit': 1,\n",
       "          'ye': 1,\n",
       "          'normal': 1,\n",
       "          'happen': 1,\n",
       "          'engin': 1,\n",
       "          'put': 1,\n",
       "          'input': 1,\n",
       "          'valid': 1,\n",
       "          'parser': 1,\n",
       "          'backend': 1,\n",
       "          'creativ': 1,\n",
       "          'director': 1,\n",
       "          'give': 1,\n",
       "          'shit': 1,\n",
       "          'long': 1,\n",
       "          'blue': 1,\n",
       "          'press': 1,\n",
       "          'releas': 1,\n",
       "          'n': 1,\n",
       "          'kk': 1,\n",
       "          'prr': 1,\n",
       "          'zzew': 1,\n",
       "          'lz': 1,\n",
       "          'ahr': 1,\n",
       "          'v': 1,\n",
       "          'l': 1,\n",
       "          'thought': 1,\n",
       "          'coldfus': 1,\n",
       "          'compatibli': 1,\n",
       "          'plugin': 1,\n",
       "          'servlet': 1,\n",
       "          'overhyp': 1,\n",
       "          'unimpl': 1,\n",
       "          'repeatedli': 1,\n",
       "          'openli': 1,\n",
       "          'rakish': 1,\n",
       "          'mb': 1,\n",
       "          'brand': 1,\n",
       "          'first': 1,\n",
       "          'download': 1,\n",
       "          'mesh': 1,\n",
       "          'well': 1,\n",
       "          'budget': 1,\n",
       "          'polici': 1}),\n",
       " Counter({'url': 5,\n",
       "          'date': 1,\n",
       "          'number': 17,\n",
       "          '_shelley': 1,\n",
       "          'powers_': 1,\n",
       "          'thought': 1,\n",
       "          'stuff': 2,\n",
       "          'weekend': 1,\n",
       "          'foaf': 3,\n",
       "          'joke': 1,\n",
       "          'bunch': 1,\n",
       "          'peopl': 1,\n",
       "          'play': 1,\n",
       "          'new': 1,\n",
       "          'toy': 1,\n",
       "          'aid': 1,\n",
       "          'aggreg': 1,\n",
       "          'author': 2,\n",
       "          'includ': 1,\n",
       "          'bit': 1,\n",
       "          'need': 1,\n",
       "          'extran': 1,\n",
       "          'materi': 1,\n",
       "          'colleg': 1,\n",
       "          'know': 4,\n",
       "          '_seth': 1,\n",
       "          'russell_': 1,\n",
       "          'exampl': 1,\n",
       "          'want': 1,\n",
       "          '_you_': 1,\n",
       "          'thing': 1,\n",
       "          'post': 1,\n",
       "          'list': 1,\n",
       "          'found': 1,\n",
       "          'email': 1,\n",
       "          'address': 1,\n",
       "          'lot': 1,\n",
       "          'read': 1,\n",
       "          'still': 1,\n",
       "          'realli': 1,\n",
       "          'project': 1,\n",
       "          'work': 1,\n",
       "          'came': 1,\n",
       "          'run': 1,\n",
       "          'mouth': 1,\n",
       "          'button': 1,\n",
       "          'feed': 1,\n",
       "          'channel': 1,\n",
       "          'well': 1,\n",
       "          'click': 1,\n",
       "          'total': 1})]"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "countres[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'saturday': 1,\n",
       "         'number': 22,\n",
       "         'septemb': 1,\n",
       "         'pm': 1,\n",
       "         'struggl': 1,\n",
       "         'free': 3,\n",
       "         'say': 2,\n",
       "         'although': 1,\n",
       "         'like': 4,\n",
       "         'total': 1,\n",
       "         'shock': 1,\n",
       "         'nine': 1,\n",
       "         'employ': 1,\n",
       "         'websit': 1,\n",
       "         'design': 1,\n",
       "         'truth': 1,\n",
       "         'webform': 1,\n",
       "         'accept': 2,\n",
       "         'u': 1,\n",
       "         'countri': 1,\n",
       "         'incred': 1,\n",
       "         'true': 1,\n",
       "         'web': 1,\n",
       "         'form': 2,\n",
       "         'also': 2,\n",
       "         'multipl': 1,\n",
       "         'even': 3,\n",
       "         'telephon': 1,\n",
       "         'partit': 1,\n",
       "         'manag': 1,\n",
       "         'step': 1,\n",
       "         'done': 1,\n",
       "         'without': 1,\n",
       "         'sell': 2,\n",
       "         'exclus': 1,\n",
       "         'right': 1,\n",
       "         'wallet': 1,\n",
       "         'world': 1,\n",
       "         'second': 1,\n",
       "         'richest': 1,\n",
       "         'corpor': 1,\n",
       "         'assum': 1,\n",
       "         'cisco': 1,\n",
       "         'still': 1,\n",
       "         'vendor': 1,\n",
       "         'lock': 1,\n",
       "         'busi': 1,\n",
       "         'small': 2,\n",
       "         'transact': 1,\n",
       "         'fee': 1,\n",
       "         'tith': 1,\n",
       "         'think': 2,\n",
       "         'peopl': 1,\n",
       "         'place': 1,\n",
       "         'would': 1,\n",
       "         'get': 3,\n",
       "         'unsolicit': 1,\n",
       "         'mail': 2,\n",
       "         'invent': 1,\n",
       "         'though': 1,\n",
       "         'perhap': 1,\n",
       "         'order': 1,\n",
       "         'enron': 1,\n",
       "         'mug': 1,\n",
       "         'king': 1,\n",
       "         'hell': 1,\n",
       "         'p': 2,\n",
       "         'met': 1,\n",
       "         'whatev': 2,\n",
       "         'commerci': 1,\n",
       "         'forum': 1,\n",
       "         'rock': 1,\n",
       "         'yesterday': 1,\n",
       "         'took': 1,\n",
       "         'greg': 1,\n",
       "         'extra': 1,\n",
       "         'serotonin': 1,\n",
       "         'lit': 1,\n",
       "         'made': 1,\n",
       "         'success': 1,\n",
       "         'go': 1,\n",
       "         'person': 1,\n",
       "         'address': 1,\n",
       "         'palett': 1,\n",
       "         'could': 1,\n",
       "         'occupi': 1,\n",
       "         'rent': 1,\n",
       "         'move': 1,\n",
       "         'repli': 1,\n",
       "         'whitepap': 1,\n",
       "         'site': 1,\n",
       "         'call': 1,\n",
       "         'real': 1,\n",
       "         'deal': 1,\n",
       "         'okay': 1,\n",
       "         'let': 1,\n",
       "         'factorytown': 1,\n",
       "         'guangzhou': 1,\n",
       "         'batteri': 1,\n",
       "         'acid': 1,\n",
       "         'supervisor': 1,\n",
       "         'multin': 1,\n",
       "         'sometim': 1,\n",
       "         'buy': 1,\n",
       "         'b': 1,\n",
       "         'e': 1,\n",
       "         'stori': 1,\n",
       "         'written': 1,\n",
       "         'way': 1,\n",
       "         'today': 1,\n",
       "         'lb': 1,\n",
       "         'tall': 1,\n",
       "         'mophead': 1,\n",
       "         'pearlec': 1,\n",
       "         'teeth': 1,\n",
       "         'excel': 1,\n",
       "         'sex': 1,\n",
       "         'link': 2,\n",
       "         'featur': 2,\n",
       "         'use': 3,\n",
       "         'solari': 1,\n",
       "         'nntp': 1,\n",
       "         'client': 1,\n",
       "         'got': 1,\n",
       "         'mere': 1,\n",
       "         'read': 1,\n",
       "         'base': 1,\n",
       "         'messag': 1,\n",
       "         'alphabet': 1,\n",
       "         'letter': 1,\n",
       "         'word': 1,\n",
       "         'come': 1,\n",
       "         'bibl': 1,\n",
       "         'calculu': 1,\n",
       "         'thank': 1,\n",
       "         'class': 1,\n",
       "         'catamit': 1,\n",
       "         'ye': 1,\n",
       "         'normal': 1,\n",
       "         'happen': 1,\n",
       "         'engin': 1,\n",
       "         'put': 1,\n",
       "         'input': 1,\n",
       "         'valid': 1,\n",
       "         'parser': 1,\n",
       "         'backend': 1,\n",
       "         'creativ': 1,\n",
       "         'director': 1,\n",
       "         'give': 1,\n",
       "         'shit': 1,\n",
       "         'long': 1,\n",
       "         'blue': 1,\n",
       "         'press': 1,\n",
       "         'releas': 1,\n",
       "         'n': 1,\n",
       "         'kk': 1,\n",
       "         'prr': 1,\n",
       "         'zzew': 1,\n",
       "         'lz': 1,\n",
       "         'ahr': 1,\n",
       "         'v': 1,\n",
       "         'l': 1,\n",
       "         'thought': 1,\n",
       "         'coldfus': 1,\n",
       "         'compatibli': 1,\n",
       "         'plugin': 1,\n",
       "         'servlet': 1,\n",
       "         'overhyp': 1,\n",
       "         'unimpl': 1,\n",
       "         'repeatedli': 1,\n",
       "         'openli': 1,\n",
       "         'rakish': 1,\n",
       "         'mb': 1,\n",
       "         'brand': 1,\n",
       "         'first': 1,\n",
       "         'download': 1,\n",
       "         'mesh': 1,\n",
       "         'well': 1,\n",
       "         'budget': 1,\n",
       "         'polici': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'On Saturday 28 September 2002 04:37 pm, you struggled free to say:\\n&> > Although it\\'s like a total shock to 99.999% (5nines) of all the\\n&> > employed website designers out there, the truth is webforms /can/\\n&> > accept \"U.S. of A\" as a country.  Incredible, but true.  Web forms can\\n&> > also accept /multiple/ or even /free-form/ telephone numbers and can\\n&> > even be partitioned into manageable steps. All this can also be done\\n&> > without selling exclusive rights to your wallet to the World\\'s\\n&> > Second-Richest Corporation (assuming Cisco is still #1) and vendor\\n&> > locking your business into their \"small transaction fee\" tithe.\\n\\nThink of all the people and places that would not get unsolicited mail\\nif we hadn\\'t invented them.  Though perhaps ordering a free Enron mug\\nas the King of Hell....\\n\\nI think it\\'s like P3P met whatever commercial /.like forum was rocking\\nyesterday, and they took all Greg\\'s extra serotonin and lit up and\\nmade a Successful go of personal address palettes you could occupy and\\nown or rent and even move or sell.  So you\\'d reply to all the whitepaper\\nsites you wouldn\\'t just call to get the real deal like: \\'Okay, let\\'s say\\nI\\'m in Factorytown, GuangZhou, and I\\'m a battery acid supervisor for\\na multinational that sometimes buys B1s.  e-mail me if you get your story\\nwritten up all the way;\\' or\\n\\t\\'Today, I\\'m a 200lb, 3m tall mophead with pearlecent teeth\\nand excellent sex-linked features, but who uses Solaris nntp clients.  Got it?\\'\\n or merely\\n\\t\\'I can\\'t read Base64 messages.  I use small alphabets and\\n8-letter words that didn\\'t come from the bible and use calculus, and\\nI\\'d thank you to class me as a Catamite.\\'\\n\\n&> Yes, but this is what normally happened:\\n&> Engineer: we can put an input validator/parser on the backend to do that.\\n&> \\t.....\\n&> Creative Director: I don\\'t give a shit. As long as it\\'s in blue. And\\n&> has a link to my press release.\\n\\nN3kk1D PRR3zzEw33Lz ahR 3V1L, but I thought it had to do with\\ncoldfusion-compatiblie plugins (servlets, whatever) that overhyped\\nunimplemented features.  Repeatedly.  Openly.  In rakish 10MB\\nbranding-first downloads that meshed well with budgeting policies.\\n\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "X_train[3].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "len({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = {'a':1,'b':2,'c':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "test1.get('d',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}