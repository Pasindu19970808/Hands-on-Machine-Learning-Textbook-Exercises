{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1> Email Classifier </h1> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the spam and valid emails are stored in 2 folders called \"easy_ham\" and \"spam\"\n",
    "#we want to read all the files in these 2 folders and pu the filenames into a list of spam and not spam\n",
    "ham_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"easy_ham\"))) if len(filename) > 20]\n",
    "spam_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"spam\"))) if len(filename) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "source": [
    "To parse emails we will use the email library of Python:\n",
    "\n",
    "How the email library works for parsing:\n",
    "\n",
    "The parser takes a serialized version of the email message(a stream of bytes) and converts it to a tree of EmailMessage objects.  The generator takes an EmailMessage and turns it back into a serialized byte stream.\n",
    "\n",
    "There are 2 parser interfaces available, the Parser API and FeedParser API. The Parser API is most useful when you have the entire text of the message in memory or if the entire message lives in a file on the file system. FeedParser API is useful when you are reading the message from a stream which might block your waiting(reading from a url itself)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all the parsed ham messages\n",
    "ham_path = os.path.join(os.getcwd(),\"easy_ham\")\n",
    "spam_path = os.path.join(os.getcwd(),\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = list()\n",
    "for filename in ham_filenames:\n",
    "    with open(os.path.join(ham_path,filename),'rb') as f:\n",
    "        ham_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = list()\n",
    "for filename in spam_filenames:\n",
    "    with open(os.path.join(spam_path,filename),'rb') as f:\n",
    "        spam_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n\n\n  | I can't reproduce this error.\n\nFor me it is very repeatable... (like every time, without fail).\n\nThis is the debug log of the pick happening ...\n\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n18:19:04 Ftoc_PickMsgs {{1 hit}}\n18:19:04 Marking 1 hits\n18:19:04 tkerror: syntax error in expression \"int ...\n\nNote, if I run the pick command by hand ...\n\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n1 hit\n\nThat's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\nusing is ...\n\ndelta$ pick -version\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n\nAnd the relevant part of my .mh_profile ...\n\ndelta$ mhparam pick\n-seq sel -list\n\n\nSince the pick command works, the sequence (actually, both of them, the\none that's explicit on the command line, from the search popup, and the\none that comes from .mh_profile) do get created.\n\nkre\n\nps: this is still using the version of the code form a day ago, I haven't\nbeen able to reach the cvs repository today (local routing issue I think).\n\n\n\n_______________________________________________\nExmh-workers mailing list\nExmh-workers@redhat.com\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\n"
     ]
    }
   ],
   "source": [
    "print(ham_messages[0].get_content().strip())"
   ]
  },
  {
   "source": [
    "Emails can have different parts to it, with images, attachments. And these attachments can have emails in them. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email,str):\n",
    "        return email\n",
    "    #get_payload() returns a list if the email is multipart and .is_multipart() = True\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload,list):\n",
    "        result = \"multipart({})\".format(', '.join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "        return result\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_counts_ham = structures_counter(ham_messages)\n",
    "structure_counts_spam = structures_counter(spam_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 2453),\n",
       " ('multipart(text/plain, application/pgp-signature)', 72),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "structure_counts_ham.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 221),\n",
       " ('text/html', 181),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 19),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "structure_counts_spam.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = list()\n",
    "temp = [[type_list.append(i) for i in structures] for structures in [structure_counts_ham, structure_counts_spam]]\n",
    "ham_type_counts = [structure_counts_ham[i] for i in set(type_list)]\n",
    "spam_type_counts = [structure_counts_spam[i] for i in set(type_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           Email Type  Ham Count  Spam Count\n",
       "0                    multipart(text/plain, video/mng)          1           0\n",
       "1                    multipart(text/plain, text/html)          8          45\n",
       "2                               multipart/alternative          0           1\n",
       "3      multipart(text/html, application/octet-stream)          0           2\n",
       "4        multipart(text/plain, multipart(text/plain))          1           0\n",
       "5                    multipart(text/html, text/plain)          0           1\n",
       "6    multipart(text/plain, application/x-java-applet)          1           0\n",
       "7                     multipart(multipart(text/html))          0           5\n",
       "8                   multipart(text/plain, text/plain)          4           0\n",
       "9   multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "10   multipart(text/plain, application/pgp-signature)         72           0\n",
       "11                               multipart(text/html)          0          19\n",
       "12                  multipart(text/plain, image/jpeg)          0           3\n",
       "13                                         text/plain       2453         221\n",
       "14  multipart(text/plain, application/x-pkcs7-sign...          1           0\n",
       "15  multipart(multipart(text/plain, text/html), im...          0           1\n",
       "16                                          text/html          0         181\n",
       "17                              multipart(text/plain)          3          19\n",
       "18    multipart(text/plain, application/octet-stream)          2           1\n",
       "19  multipart(text/plain, application/ms-tnef, tex...          1           0\n",
       "20               multipart(text/plain, text/enriched)          1           0\n",
       "21  multipart(multipart(text/plain, text/plain, te...          1           0\n",
       "22  multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "23  multipart(multipart(text/html), application/oc...          0           1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Email Type</th>\n      <th>Ham Count</th>\n      <th>Spam Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>multipart(text/plain, video/mng)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>multipart(text/plain, text/html)</td>\n      <td>8</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>multipart/alternative</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>multipart(text/html, application/octet-stream)</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multipart(text/plain, multipart(text/plain))</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>multipart(text/html, text/plain)</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>multipart(text/plain, application/x-java-applet)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>multipart(multipart(text/html))</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>multipart(text/plain, text/plain)</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>multipart(text/plain, application/pgp-signature)</td>\n      <td>72</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>multipart(text/html)</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>multipart(text/plain, image/jpeg)</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>text/plain</td>\n      <td>2453</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>multipart(text/plain, application/x-pkcs7-sign...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>multipart(multipart(text/plain, text/html), im...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>text/html</td>\n      <td>0</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>multipart(text/plain)</td>\n      <td>3</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>multipart(text/plain, application/octet-stream)</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>multipart(text/plain, application/ms-tnef, tex...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>multipart(text/plain, text/enriched)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>multipart(multipart(text/plain, text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>multipart(multipart(text/html), application/oc...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "type_counts_df = pd.DataFrame({'Email Type':list(set(type_list)), 'Ham Count':ham_type_counts, 'Spam Count':spam_type_counts})\n",
    "type_counts_df"
   ]
  },
  {
   "source": [
    "Most valid(ham) emails are text/plain and contain a PGP(Pretty Good Privacy) signature, while Spam emails have a higher amount of HTML messages. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of type of each email \n",
    "ham_email_type = [get_email_structure(email) for email in ham_messages]\n",
    "spam_email_type = [get_email_structure(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindEmailSender(email):\n",
    "    try:\n",
    "        return dict(email.items())['From']\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of senders of each email\n",
    "ham_email_senders = [FindEmailSender(email) for email in ham_messages]\n",
    "spam_email_senders = [FindEmailSender(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the dataset to create a complete dataset for splitting into train and test sets\n",
    "import numpy as np\n",
    "X = np.array(ham_messages + spam_messages, dtype = object)\n",
    "y = np.array([0] * len(ham_messages) + [1]*len(spam_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning html in emails into tags we want\n",
    "#turn head tags into ''\n",
    "#turn anchor tags into hyper links\n",
    "#turn all html tags into ''\n",
    "import re\n",
    "from html import unescape\n",
    "def html_to_text(html):\n",
    "    text = re.sub(r'<head.*?>.*?</head>','',html,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<a.*?>.*?</a>',' HYPERLINK ',text,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<.*?>','',text,flags=re.M|re.I|re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+','\\n',text,flags = re.M|re.I|re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_html = [i for i in range(len(X_train)) if get_email_structure(X_train[i]) == 'text/html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n HYPERLINK\\nCopyright 2002 - All rights reservedIf you would no longer like us\\nto contact you or feel that you havereceived this email in error,\\nplease  HYPERLINK .'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "html_to_text(X_train[idx_html[5]].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[41, 805, 942, 1131, 1219, 2033, 2134, 2266]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#check if any EmailMessage objects have more tha one text/html type occuring\n",
    "html_check = list()\n",
    "for j in range(len(X_train)):\n",
    "    i = 0\n",
    "    for part in X_train[j].walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            i += 1\n",
    "        if i == 2:\n",
    "            html_check.append(j)\n",
    "    \n",
    "html_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for sub_email in email.walk():\n",
    "        content_type = sub_email.get_content_type()\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text_multipart(email,f,i):\n",
    "    html = None\n",
    "    #the first sub_email that is traversed is the main parent email itself. the following will be the children\n",
    "    for sub_email in email.walk():\n",
    "        content_type = sub_email.get_content_type()\n",
    "        f.write('{},{}\\n'.format(i,content_type))\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            #if the parent mail is multipart, use this route\n",
    "            content_type = email.get_content_type()\n",
    "            if re.fullmatch(r'multipart/[a-zA-Z]+',content_type) != None:\n",
    "                textlist = list()\n",
    "                for sub_email_1 in email.get_payload():\n",
    "                    try:\n",
    "                        if sub_email_1.get_content_type() == 'text/plain':\n",
    "                            textlist.append(sub_email_1.get_content())\n",
    "                        elif sub_email_1.get_content_type() == 'text/html':\n",
    "                            textlist.append(html_to_text(sub_email_1.get_content()))\n",
    "                        else:\n",
    "                            continue\n",
    "                    except:\n",
    "                        if(isinstance(sub_email_1,str)):\n",
    "                            textlist.append(sub_email_1)\n",
    "                        else:\n",
    "                            continue\n",
    "                if (len(textlist) > 0):\n",
    "                    return ' '.join(textlist)\n",
    "            else:\n",
    "                continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            f.write('{},{}\\n'.format(i,content_type))\n",
    "            html = content\n",
    "    if html:\n",
    "        try:\n",
    "            return html_to_text(html)\n",
    "        except:\n",
    "            f.write('{},{}\\n'.format(i,html))\n",
    "            f.close()\n",
    "            return TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text_multipart_2(email,f,i):\n",
    "    html = None\n",
    "    email_type = email.get_content_type()\n",
    "    #j is used as a counter to count on the walk attribute\n",
    "    textlist = list()\n",
    "    j = 0\n",
    "    for sub_email in email.walk():\n",
    "        j += 1\n",
    "        sub_type = sub_email.get_content_type()\n",
    "        f.write('{},{}\\n'.format(i,sub_type))\n",
    "        if sub_type not in ('text/plain','text/html'):\n",
    "            #if the parent is not text/plain or text/html we want to continue\n",
    "            continue\n",
    "        #this is to get the content if the parent is text/html or text/plain\n",
    "        elif ((j==1) & (sub_type in ('text/plain','text/html')) & (re.fullmatch(r'multipart/[a-zA-Z]+',email_type) == None)):\n",
    "            try:\n",
    "                content = sub_email.get_content()\n",
    "            except:\n",
    "                content = str(sub_email.get_payload())\n",
    "            if (sub_type == 'text/plain'):\n",
    "                f.write('{},2nd Condition,{},{}\\n'.format(i,email_type,sub_type))\n",
    "                return content\n",
    "            else:\n",
    "                html = content\n",
    "                return html_to_text(html)\n",
    "        elif ((j!=1) & ((r'multipart/[a-zA-Z]+',email_type) != None)):\n",
    "            f.write('{},MULTIPART,{}\\n'.format(i,sub_type))\n",
    "            try:\n",
    "                if sub_type == 'text/plain':\n",
    "                    f.write('{},wrote to textlist,{},{},j:{}\\n'.format(i,sub_type,len(textlist),j))\n",
    "                    textlist.append(sub_email.get_content())\n",
    "                elif sub_type == 'text/html':\n",
    "                    f.write('{},wrote to textlist,{},{},j:{}\\n'.format(i,sub_type,len(textlist),j))\n",
    "                    textlist.append(html_to_text(sub_email.get_content()))\n",
    "                elif(sub_type not in ('text/plain','text/html')):\n",
    "                    f.write('Not text/html or text/plain \\n')\n",
    "                    continue\n",
    "            except:\n",
    "                if(isinstance(sub_email,str)):\n",
    "                    f.write('{},wrote to textlist as string,{},{}\\n'.format(i,sub_type,len(textlist)))\n",
    "                    textlist.append(sub_email)\n",
    "                else:\n",
    "                    continue\n",
    "    if (len(textlist) > 0):\n",
    "        return ' '.join(textlist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts emails in the body to \"EMAIL\"\n",
    "import re\n",
    "def convert_email_tags(email_text):\n",
    "    return re.sub(r'([a-zA-Z0-9\\._-]+@[a-zA-Z0-9\\._-]+\\.[a-zA-Z0-9\\._-]+)',' EMAIL ',email_text,flags = re.I|re.S|re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(email_text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(email_text.strip())\n",
    "    return [i for i in words if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the words to get the root of words\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemmer(email_word_list):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(w) for w in email_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "class EmailToWord(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,lower_case = True, remove_email = True, remove_punctuation = True, remove_urls = True, stemming = True, remove_stopwords = True, remove_numbers = True):\n",
    "         self.lower_case =lower_case\n",
    "         self.remove_email = remove_email\n",
    "         self.remove_punctuation = remove_punctuation\n",
    "         self.remove_urls = remove_urls\n",
    "         self.stemming = stemming\n",
    "         self.remove_stopwords = remove_stopwords\n",
    "         self.remove_numbers = remove_numbers\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        X_transformed = []\n",
    "        with open('log.txt','w') as f:\n",
    "            for i,email in enumerate(X):\n",
    "                text = email_to_text_multipart_2(email,f,i) or \"\"\n",
    "                if self.lower_case:\n",
    "                    text = text.lower()\n",
    "                if self.remove_urls:\n",
    "                    url_extractor = urlextract.URLExtract()\n",
    "                    urls = url_extractor.find_urls(text)\n",
    "                    for url in urls:\n",
    "                        text = text.replace(url,' URL ')\n",
    "                if self.remove_punctuation:\n",
    "                    text = re.sub(r'[^a-zA-Z0-9_]',' ', text, flags = re.M|re.S|re.I)\n",
    "                if self.remove_numbers:\n",
    "                    text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', ' NUMBER ', text, flags = re.I|re.S|re.M)\n",
    "                if self.remove_email:\n",
    "                    text = convert_email_tags(text)\n",
    "                if self.remove_stopwords:\n",
    "                    #words without stemming\n",
    "                    word_list = remove_stopwords(text)\n",
    "                if self.stemming:\n",
    "                    stemmed_list = stemmer(word_list)\n",
    "                X_transformed.append(stemmed_list)\n",
    "        return X_transformed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "from collections import Counter\n",
    "class CountWords(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        #create a word vector\n",
    "        X_wordcounts = []\n",
    "        for email_word_list in X:\n",
    "            X_wordcounts.append(Counter(email_word_list))\n",
    "        #returns a Counter object\n",
    "        return X_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "class CreateWordVector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,vocabulary_size = 1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self,X,y=None):\n",
    "        total_count = Counter()\n",
    "        for email in X:\n",
    "            #each email is a counter object here\n",
    "            for word,count in email.items():\n",
    "                total_count[word] += min(count,10)\n",
    "        self.most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word:index + 1 for index,(word,count) in enumerate(self.most_common)}\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        occurences = []\n",
    "        result_array = np.zeros(shape = (len(X),self.vocabulary_size + 1))\n",
    "        for i,email in enumerate(X):\n",
    "            for word,count in email.items():\n",
    "                #getting the index position for the word in most common dictionary. This will be used as the entry to cols\n",
    "                idx = self.vocabulary_.get(word,0)\n",
    "                if idx == 0:\n",
    "                    result_array[i,0] = result_array[i,0] + count\n",
    "                else:\n",
    "                    result_array[i,idx] = result_array[i,idx] + count  \n",
    "        return [result_array,self.most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "datatransformation = Pipeline([\n",
    "    ('emailtoword',EmailToWord()),\n",
    "    ('countwords',CountWords()),\n",
    "    ('createwordvector',CreateWordVector())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = datatransformation.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = res[0]\n",
    "most_common = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 237
    }
   ],
   "source": [
    "len(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe from the data we have obtained of the transformed emails\n",
    "import pandas as pd\n",
    "columns = [i[0] for i in most_common]\n",
    "columns.insert(0,'Not in Vocabulary')\n",
    "X_train_transformed_df = pd.DataFrame(data = X_train_transformed,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Not in Vocabulary  number  url  list  use  mail  get  one  time  like  \\\n",
       "0                  11.0     0.0  1.0   0.0  0.0   0.0  0.0  0.0   0.0   0.0   \n",
       "1                  18.0    10.0  1.0   1.0  0.0   1.0  0.0  0.0   2.0   0.0   \n",
       "2                  22.0     0.0  0.0   0.0  0.0   0.0  1.0  0.0   0.0   0.0   \n",
       "3                  77.0    22.0  0.0   0.0  3.0   2.0  3.0  0.0   0.0   4.0   \n",
       "4                  19.0    17.0  5.0   1.0  0.0   0.0  0.0  0.0   0.0   0.0   \n",
       "...                 ...     ...  ...   ...  ...   ...  ...  ...   ...   ...   \n",
       "2435               14.0     6.0  4.0   2.0  1.0   2.0  1.0  1.0   1.0   0.0   \n",
       "2436               43.0    11.0  1.0   1.0  3.0   1.0  1.0  3.0   0.0   1.0   \n",
       "2437                9.0     1.0  2.0   3.0  0.0   1.0  0.0  0.0   0.0   0.0   \n",
       "2438               16.0    11.0  1.0   3.0  0.0   1.0  1.0  0.0   0.0   0.0   \n",
       "2439               78.0    10.0  2.0   1.0  1.0   0.0  3.0  1.0   0.0   3.0   \n",
       "\n",
       "      ...  owner  decis  expert  match  btw  middl  mode  effici  startup  \\\n",
       "0     ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "1     ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "2     ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "3     ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "4     ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "...   ...    ...    ...     ...    ...  ...    ...   ...     ...      ...   \n",
       "2435  ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "2436  ...    0.0    0.0     0.0    0.0  1.0    0.0   0.0     0.0      0.0   \n",
       "2437  ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "2438  ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "2439  ...    0.0    0.0     0.0    0.0  0.0    0.0   0.0     0.0      0.0   \n",
       "\n",
       "      Result  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "2435       0  \n",
       "2436       0  \n",
       "2437       0  \n",
       "2438       0  \n",
       "2439       0  \n",
       "\n",
       "[2440 rows x 1002 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Not in Vocabulary</th>\n      <th>number</th>\n      <th>url</th>\n      <th>list</th>\n      <th>use</th>\n      <th>mail</th>\n      <th>get</th>\n      <th>one</th>\n      <th>time</th>\n      <th>like</th>\n      <th>...</th>\n      <th>owner</th>\n      <th>decis</th>\n      <th>expert</th>\n      <th>match</th>\n      <th>btw</th>\n      <th>middl</th>\n      <th>mode</th>\n      <th>effici</th>\n      <th>startup</th>\n      <th>Result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>77.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19.0</td>\n      <td>17.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2435</th>\n      <td>14.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2436</th>\n      <td>43.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2437</th>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2438</th>\n      <td>16.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2439</th>\n      <td>78.0</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2440 rows Ã— 1002 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "X_train_transformed_df['Result'] = y_train\n",
    "X_train_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing histogram for spam email and normal email to see word distributions. \n",
    "#words not in vocabulary will be left out and we shall only draw for the most occuring 20 words in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}