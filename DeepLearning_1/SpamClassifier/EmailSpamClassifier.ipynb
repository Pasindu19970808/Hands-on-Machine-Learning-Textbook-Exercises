{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1> Email Classifier </h1> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the spam and valid emails are stored in 2 folders called \"easy_ham\" and \"spam\"\n",
    "#we want to read all the files in these 2 folders and pu the filenames into a list of spam and not spam\n",
    "ham_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"easy_ham\"))) if len(filename) > 20]\n",
    "spam_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"spam\"))) if len(filename) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "source": [
    "To parse emails we will use the email library of Python:\n",
    "\n",
    "How the email library works for parsing:\n",
    "\n",
    "The parser takes a serialized version of the email message(a stream of bytes) and converts it to a tree of EmailMessage objects.  The generator takes an EmailMessage and turns it back into a serialized byte stream.\n",
    "\n",
    "There are 2 parser interfaces available, the Parser API and FeedParser API. The Parser API is most useful when you have the entire text of the message in memory or if the entire message lives in a file on the file system. FeedParser API is useful when you are reading the message from a stream which might block your waiting(reading from a url itself)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all the parsed ham messages\n",
    "ham_path = os.path.join(os.getcwd(),\"easy_ham\")\n",
    "spam_path = os.path.join(os.getcwd(),\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = list()\n",
    "for filename in ham_filenames:\n",
    "    with open(os.path.join(ham_path,filename),'rb') as f:\n",
    "        ham_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = list()\n",
    "for filename in spam_filenames:\n",
    "    with open(os.path.join(spam_path,filename),'rb') as f:\n",
    "        spam_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n\n\n  | I can't reproduce this error.\n\nFor me it is very repeatable... (like every time, without fail).\n\nThis is the debug log of the pick happening ...\n\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n18:19:04 Ftoc_PickMsgs {{1 hit}}\n18:19:04 Marking 1 hits\n18:19:04 tkerror: syntax error in expression \"int ...\n\nNote, if I run the pick command by hand ...\n\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n1 hit\n\nThat's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\nusing is ...\n\ndelta$ pick -version\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n\nAnd the relevant part of my .mh_profile ...\n\ndelta$ mhparam pick\n-seq sel -list\n\n\nSince the pick command works, the sequence (actually, both of them, the\none that's explicit on the command line, from the search popup, and the\none that comes from .mh_profile) do get created.\n\nkre\n\nps: this is still using the version of the code form a day ago, I haven't\nbeen able to reach the cvs repository today (local routing issue I think).\n\n\n\n_______________________________________________\nExmh-workers mailing list\nExmh-workers@redhat.com\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\n"
     ]
    }
   ],
   "source": [
    "print(ham_messages[0].get_content().strip())"
   ]
  },
  {
   "source": [
    "Emails can have different parts to it, with images, attachments. And these attachments can have emails in them. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email,str):\n",
    "        return email\n",
    "    #get_payload() returns a list if the email is multipart and .is_multipart() = True\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload,list):\n",
    "        result = \"multipart({})\".format(', '.join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "        return result\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_counts_ham = structures_counter(ham_messages)\n",
    "structure_counts_spam = structures_counter(spam_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 2453),\n",
       " ('multipart(text/plain, application/pgp-signature)', 72),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "structure_counts_ham.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 221),\n",
       " ('text/html', 181),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 19),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "structure_counts_spam.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = list()\n",
    "temp = [[type_list.append(i) for i in structures] for structures in [structure_counts_ham, structure_counts_spam]]\n",
    "ham_type_counts = [structure_counts_ham[i] for i in set(type_list)]\n",
    "spam_type_counts = [structure_counts_spam[i] for i in set(type_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           Email Type  Ham Count  Spam Count\n",
       "0                    multipart(text/plain, video/mng)          1           0\n",
       "1                    multipart(text/plain, text/html)          8          45\n",
       "2                               multipart/alternative          0           1\n",
       "3      multipart(text/html, application/octet-stream)          0           2\n",
       "4        multipart(text/plain, multipart(text/plain))          1           0\n",
       "5                    multipart(text/html, text/plain)          0           1\n",
       "6    multipart(text/plain, application/x-java-applet)          1           0\n",
       "7                     multipart(multipart(text/html))          0           5\n",
       "8                   multipart(text/plain, text/plain)          4           0\n",
       "9   multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "10   multipart(text/plain, application/pgp-signature)         72           0\n",
       "11                               multipart(text/html)          0          19\n",
       "12                  multipart(text/plain, image/jpeg)          0           3\n",
       "13                                         text/plain       2453         221\n",
       "14  multipart(text/plain, application/x-pkcs7-sign...          1           0\n",
       "15  multipart(multipart(text/plain, text/html), im...          0           1\n",
       "16                                          text/html          0         181\n",
       "17                              multipart(text/plain)          3          19\n",
       "18    multipart(text/plain, application/octet-stream)          2           1\n",
       "19  multipart(text/plain, application/ms-tnef, tex...          1           0\n",
       "20               multipart(text/plain, text/enriched)          1           0\n",
       "21  multipart(multipart(text/plain, text/plain, te...          1           0\n",
       "22  multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "23  multipart(multipart(text/html), application/oc...          0           1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Email Type</th>\n      <th>Ham Count</th>\n      <th>Spam Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>multipart(text/plain, video/mng)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>multipart(text/plain, text/html)</td>\n      <td>8</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>multipart/alternative</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>multipart(text/html, application/octet-stream)</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multipart(text/plain, multipart(text/plain))</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>multipart(text/html, text/plain)</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>multipart(text/plain, application/x-java-applet)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>multipart(multipart(text/html))</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>multipart(text/plain, text/plain)</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>multipart(text/plain, application/pgp-signature)</td>\n      <td>72</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>multipart(text/html)</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>multipart(text/plain, image/jpeg)</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>text/plain</td>\n      <td>2453</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>multipart(text/plain, application/x-pkcs7-sign...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>multipart(multipart(text/plain, text/html), im...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>text/html</td>\n      <td>0</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>multipart(text/plain)</td>\n      <td>3</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>multipart(text/plain, application/octet-stream)</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>multipart(text/plain, application/ms-tnef, tex...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>multipart(text/plain, text/enriched)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>multipart(multipart(text/plain, text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>multipart(multipart(text/html), application/oc...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "type_counts_df = pd.DataFrame({'Email Type':list(set(type_list)), 'Ham Count':ham_type_counts, 'Spam Count':spam_type_counts})\n",
    "type_counts_df"
   ]
  },
  {
   "source": [
    "Most valid(ham) emails are text/plain and contain a PGP(Pretty Good Privacy) signature, while Spam emails have a higher amount of HTML messages. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of type of each email \n",
    "ham_email_type = [get_email_structure(email) for email in ham_messages]\n",
    "spam_email_type = [get_email_structure(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindEmailSender(email):\n",
    "    try:\n",
    "        return dict(email.items())['From']\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of senders of each email\n",
    "ham_email_senders = [FindEmailSender(email) for email in ham_messages]\n",
    "spam_email_senders = [FindEmailSender(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the dataset to create a complete dataset for splitting into train and test sets\n",
    "import numpy as np\n",
    "X = np.array(ham_messages + spam_messages, dtype = object)\n",
    "y = np.array([0] * len(ham_messages) + [1]*len(spam_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning html in emails into tags we want\n",
    "#turn head tags into ''\n",
    "#turn anchor tags into hyper links\n",
    "#turn all html tags into ''\n",
    "import re\n",
    "from html import unescape\n",
    "def html_to_text(html):\n",
    "    text = re.sub(r'<head.*?>.*?</head>','',html,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<a.*?>.*?</a>',' HYPERLINK ',text,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<.*?>','',text,flags=re.M|re.I|re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+','\\n',text,flags = re.M|re.I|re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_html = [i for i in range(len(X_train)) if get_email_structure(X_train[i]) == 'text/html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n HYPERLINK\\nCopyright 2002 - All rights reservedIf you would no longer like us\\nto contact you or feel that you havereceived this email in error,\\nplease  HYPERLINK .'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "html_to_text(X_train[idx_html[5]].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[41, 805, 942, 1131, 1219, 2033, 2134, 2266]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#check if any EmailMessage objects have more tha one text/html type occuring\n",
    "html_check = list()\n",
    "for j in range(len(X_train)):\n",
    "    i = 0\n",
    "    for part in X_train[j].walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            i += 1\n",
    "        if i == 2:\n",
    "            html_check.append(j)\n",
    "    \n",
    "html_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for sub_email in email.walk():\n",
    "        content_type = sub_email.get_content_type()\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text_multipart(email):\n",
    "    html = None\n",
    "    #the first sub_email that is traversed is the main parent email itself. the following will be the children\n",
    "    for sub_email in email.walk():\n",
    "        content_type = sub_email.get_content_type()\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            #if the parent mail is multipart, use this route\n",
    "            content_type = email.get_content_type()\n",
    "            if re.fullmatch(r'multipart/[a-zA-Z]+',content_type) != None:\n",
    "                textlist = list()\n",
    "                for sub_email_1 in email.get_payload():\n",
    "                    if sub_email_1.get_content_type() == 'text/plain':\n",
    "                        textlist.append(sub_email_1.get_content())\n",
    "                    elif sub_email_1.get_content_type() == 'text/html':\n",
    "                        textlist.append(html_to_text(sub_email_1.get_content()))\n",
    "                    else:\n",
    "                        continue\n",
    "                if (len(textlist) > 0):\n",
    "                    return ' '.join(textlist)\n",
    "            else:\n",
    "                continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts emails in the body to \"EMAIL\"\n",
    "import re\n",
    "def convert_email_tags(email_text):\n",
    "    return re.sub(r'([a-zA-Z0-9\\._-]+@[a-zA-Z0-9\\._-]+\\.[a-zA-Z0-9\\._-]+)',' EMAIL ',email_text,flags = re.I|re.S|re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(email_text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(email_text.strip())\n",
    "    return [i for i in words if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the words to get the root of words\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemmer(email_word_list):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(w) for w in email_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "class EmailToWord(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,lower_case = True, remove_email = True, remove_punctuation = True, remove_urls = True, stemming = True, remove_stopwords = True, remove_numbers = True):\n",
    "         self.lower_case =lower_case\n",
    "         self.remove_email = remove_email\n",
    "         self.remove_punctuation = remove_punctuation\n",
    "         self.remove_urls = remove_urls\n",
    "         self.stemming = stemming\n",
    "         self.remove_stopwords = remove_stopwords\n",
    "         self.remove_numbers = remove_numbers\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text_multipart(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.remove_urls:\n",
    "                url_extractor = urlextract.URLExtract()\n",
    "                urls = url_extractor.find_urls(text)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url,' URL ')\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'[^a-zA-Z0-9_]',' ', text, flags = re.M|re.S|re.I)\n",
    "            if self.remove_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', ' NUMBER ', text, flags = re.I|re.S|re.M)\n",
    "            if self.remove_email:\n",
    "                text = convert_email_tags(text)\n",
    "            if self.remove_stopwords:\n",
    "                #words without stemming\n",
    "                word_list = remove_stopwords(text)\n",
    "            if self.stemming:\n",
    "                stemmed_list = stemmer(word_list)\n",
    "            X_transformed.append(stemmed_list)\n",
    "        return X_transformed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "from collections import Counter\n",
    "class CountWords(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        #create a word vector\n",
    "        X_wordcounts = []\n",
    "        for email_word_list in X:\n",
    "            X_wordcounts.append(Counter(email_word_list))\n",
    "        return X_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailtowords = EmailToWord()\n",
    "test = emailtowords.fit_transform(X_train[:100])\n",
    "countwords = CountWords()\n",
    "countres = countwords.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "class CreateWordVector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,vocabulary_size = 1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self,X,y=None):\n",
    "        total_count = Counter()\n",
    "        for email in X:\n",
    "            for word,count in email.items():\n",
    "                total_count[word] += min(count,10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word:index + 1 for index,(word,count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        occurences = []\n",
    "        for i,email in enumerate(X):\n",
    "            for word,count in email.items():\n",
    "                #getting the index position for the word in most common dictionary. This will be used as the entry to cols\n",
    "                cols.append(self.vocabulary_.get(word,0))\n",
    "                rows.append(i)\n",
    "                occurences.append(count)\n",
    "        return csr_matrix((occurences,(rows,cols)), shape =(len(X),self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 7.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [17., 10.,  1., ...,  0.,  0.,  0.],\n",
       "       [17.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "createwordvectest = CreateWordVector()\n",
    "createwordvectest.fit_transform(countres)[:3].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "class CreateWordVector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,vocabulary_size = 1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self,X,y=None):\n",
    "        total_count = Counter()\n",
    "        for email in X:\n",
    "            for word,count in email.items():\n",
    "                total_count[word] += min(count,10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word:index + 1 for index,(word,count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        occurences = []\n",
    "        result_array = np.empty(shape = (X.shape[0],self.vocabulary_ + 1))\n",
    "        for i,email in enumerate(X):\n",
    "            for word,count in email.items():\n",
    "                #getting the index position for the word in most common dictionary. This will be used as the entry to cols\n",
    "                idx = self.vocabulary_.get(word,0)\n",
    "                if idx == 0:\n",
    "                    result_array[i,0] = result_array[i,0] + count\n",
    "                else:\n",
    "                    result_array[i,idx] = result_array[i,idx] + count  \n",
    "        return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-80c1cd9038e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcreatewordvectest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCreateWordVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcreatewordvectest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-70513b2e0392>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moccurences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mresult_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memail\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memail\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "createwordvectest = CreateWordVector()\n",
    "createwordvectest.fit_transform(countres)[:3].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[6.23042070e-307, 4.67296746e-307, 1.69121096e-306,\n",
       "        4.67293691e-307, 1.42413555e-306],\n",
       "       [1.78019082e-306, 1.37959740e-306, 6.23057349e-307,\n",
       "        1.02360935e-306, 1.69120416e-306],\n",
       "       [1.78022342e-306, 6.23058028e-307, 1.06811422e-306,\n",
       "        1.33508761e-307, 8.01097889e-307],\n",
       "       [7.56599128e-307, 6.89804132e-307, 1.11261162e-306,\n",
       "        8.34443015e-308, 1.37954579e-306]])"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0] = np.array([2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-30dd07d0a704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "test1 = list()\n",
    "test1[0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}