{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1> Email Classifier </h1> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the spam and valid emails are stored in 2 folders called \"easy_ham\" and \"spam\"\n",
    "#we want to read all the files in these 2 folders and pu the filenames into a list of spam and not spam\n",
    "ham_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"easy_ham\"))) if len(filename) > 20]\n",
    "spam_filenames = [filename for filename in sorted(os.listdir(os.path.join(os.getcwd(),\"spam\"))) if len(filename) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "source": [
    "To parse emails we will use the email library of Python:\n",
    "\n",
    "How the email library works for parsing:\n",
    "\n",
    "The parser takes a serialized version of the email message(a stream of bytes) and converts it to a tree of EmailMessage objects.  The generator takes an EmailMessage and turns it back into a serialized byte stream.\n",
    "\n",
    "There are 2 parser interfaces available, the Parser API and FeedParser API. The Parser API is most useful when you have the entire text of the message in memory or if the entire message lives in a file on the file system. FeedParser API is useful when you are reading the message from a stream which might block your waiting(reading from a url itself)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all the parsed ham messages\n",
    "ham_path = os.path.join(os.getcwd(),\"easy_ham\")\n",
    "spam_path = os.path.join(os.getcwd(),\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email import policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = list()\n",
    "for filename in ham_filenames:\n",
    "    with open(os.path.join(ham_path,filename),'rb') as f:\n",
    "        ham_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_messages = list()\n",
    "for filename in spam_filenames:\n",
    "    with open(os.path.join(spam_path,filename),'rb') as f:\n",
    "        spam_messages.append(email.parser.BytesParser(policy = email.policy.default).parse(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n\n\n  | I can't reproduce this error.\n\nFor me it is very repeatable... (like every time, without fail).\n\nThis is the debug log of the pick happening ...\n\n18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n18:19:04 Ftoc_PickMsgs {{1 hit}}\n18:19:04 Marking 1 hits\n18:19:04 tkerror: syntax error in expression \"int ...\n\nNote, if I run the pick command by hand ...\n\ndelta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n1 hit\n\nThat's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\nusing is ...\n\ndelta$ pick -version\npick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n\nAnd the relevant part of my .mh_profile ...\n\ndelta$ mhparam pick\n-seq sel -list\n\n\nSince the pick command works, the sequence (actually, both of them, the\none that's explicit on the command line, from the search popup, and the\none that comes from .mh_profile) do get created.\n\nkre\n\nps: this is still using the version of the code form a day ago, I haven't\nbeen able to reach the cvs repository today (local routing issue I think).\n\n\n\n_______________________________________________\nExmh-workers mailing list\nExmh-workers@redhat.com\nhttps://listman.redhat.com/mailman/listinfo/exmh-workers\n"
     ]
    }
   ],
   "source": [
    "print(ham_messages[0].get_content().strip())"
   ]
  },
  {
   "source": [
    "Emails can have different parts to it, with images, attachments. And these attachments can have emails in them. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email,str):\n",
    "        return email\n",
    "    #get_payload() returns a list if the email is multipart and .is_multipart() = True\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload,list):\n",
    "        result = \"multipart({})\".format(', '.join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "        return result\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_counts_ham = structures_counter(ham_messages)\n",
    "structure_counts_spam = structures_counter(spam_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 2453),\n",
       " ('multipart(text/plain, application/pgp-signature)', 72),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "structure_counts_ham.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('text/plain', 221),\n",
       " ('text/html', 181),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 19),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "structure_counts_spam.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = list()\n",
    "temp = [[type_list.append(i) for i in structures] for structures in [structure_counts_ham, structure_counts_spam]]\n",
    "ham_type_counts = [structure_counts_ham[i] for i in set(type_list)]\n",
    "spam_type_counts = [structure_counts_spam[i] for i in set(type_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           Email Type  Ham Count  Spam Count\n",
       "0   multipart(multipart(text/plain, text/html), im...          0           1\n",
       "1   multipart(multipart(text/plain, text/plain, te...          1           0\n",
       "2    multipart(text/plain, application/x-java-applet)          1           0\n",
       "3                   multipart(text/plain, text/plain)          4           0\n",
       "4   multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "5                    multipart(text/plain, text/html)          8          45\n",
       "6      multipart(text/html, application/octet-stream)          0           2\n",
       "7   multipart(text/plain, application/x-pkcs7-sign...          1           0\n",
       "8    multipart(text/plain, application/pgp-signature)         72           0\n",
       "9                    multipart(text/plain, video/mng)          1           0\n",
       "10                    multipart(multipart(text/html))          0           5\n",
       "11                              multipart(text/plain)          3          19\n",
       "12                                          text/html          0         181\n",
       "13                  multipart(text/plain, image/jpeg)          0           3\n",
       "14  multipart(text/plain, multipart(text/plain, te...          1           0\n",
       "15  multipart(text/plain, application/ms-tnef, tex...          1           0\n",
       "16       multipart(text/plain, multipart(text/plain))          1           0\n",
       "17               multipart(text/plain, text/enriched)          1           0\n",
       "18    multipart(text/plain, application/octet-stream)          2           1\n",
       "19                   multipart(text/html, text/plain)          0           1\n",
       "20                               multipart(text/html)          0          19\n",
       "21                                         text/plain       2453         221\n",
       "22  multipart(multipart(text/html), application/oc...          0           1\n",
       "23                              multipart/alternative          0           1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Email Type</th>\n      <th>Ham Count</th>\n      <th>Spam Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>multipart(multipart(text/plain, text/html), im...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>multipart(multipart(text/plain, text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>multipart(text/plain, application/x-java-applet)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>multipart(text/plain, text/plain)</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>multipart(text/plain, text/html)</td>\n      <td>8</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>multipart(text/html, application/octet-stream)</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>multipart(text/plain, application/x-pkcs7-sign...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>multipart(text/plain, application/pgp-signature)</td>\n      <td>72</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>multipart(text/plain, video/mng)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>multipart(multipart(text/html))</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>multipart(text/plain)</td>\n      <td>3</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>text/html</td>\n      <td>0</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>multipart(text/plain, image/jpeg)</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>multipart(text/plain, multipart(text/plain, te...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>multipart(text/plain, application/ms-tnef, tex...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>multipart(text/plain, multipart(text/plain))</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>multipart(text/plain, text/enriched)</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>multipart(text/plain, application/octet-stream)</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>multipart(text/html, text/plain)</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>multipart(text/html)</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>text/plain</td>\n      <td>2453</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>multipart(multipart(text/html), application/oc...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>multipart/alternative</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "type_counts_df = pd.DataFrame({'Email Type':list(set(type_list)), 'Ham Count':ham_type_counts, 'Spam Count':spam_type_counts})\n",
    "type_counts_df"
   ]
  },
  {
   "source": [
    "Most valid(ham) emails are text/plain and contain a PGP(Pretty Good Privacy) signature, while Spam emails have a higher amount of HTML messages. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of type of each email \n",
    "ham_email_type = [get_email_structure(email) for email in ham_messages]\n",
    "spam_email_type = [get_email_structure(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindEmailSender(email):\n",
    "    try:\n",
    "        return dict(email.items())['From']\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of senders of each email\n",
    "ham_email_senders = [FindEmailSender(email) for email in ham_messages]\n",
    "spam_email_senders = [FindEmailSender(email) for email in spam_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the dataset to create a complete dataset for splitting into train and test sets\n",
    "import numpy as np\n",
    "X = np.array(ham_messages + spam_messages, dtype = object)\n",
    "y = np.array([0] * len(ham_messages) + [1]*len(spam_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning html in emails into tags we want\n",
    "#turn head tags into ''\n",
    "#turn anchor tags into hyper links\n",
    "#turn all html tags into ''\n",
    "import re\n",
    "from html import unescape\n",
    "def html_to_text(html):\n",
    "    text = re.sub(r'<head.*?>.*?</head>','',html,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<a.*?>.*?</a>',' HYPERLINK ',text,flags = re.I|re.M|re.S)\n",
    "    text = re.sub(r'<.*?>','',text,flags=re.M|re.I|re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+','\\n',text,flags = re.M|re.I|re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_html = [i for i in range(len(X_train)) if get_email_structure(X_train[i]) == 'text/html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n HYPERLINK\\nCopyright 2002 - All rights reservedIf you would no longer like us\\nto contact you or feel that you havereceived this email in error,\\nplease  HYPERLINK .'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "html_to_text(X_train[idx_html[5]].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[41, 805, 942, 1131, 1219, 2033, 2134, 2266]"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "#check if any EmailMessage objects have more tha one text/html type occuring\n",
    "html_check = list()\n",
    "for j in range(len(X_train)):\n",
    "    i = 0\n",
    "    for part in X_train[j].walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            i += 1\n",
    "        if i == 2:\n",
    "            html_check.append(j)\n",
    "    \n",
    "html_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for sub_email in email.walk():\n",
    "        content_type = email.get_content_type()\n",
    "        if content_type not in ('text/html','text/plain'):\n",
    "            continue\n",
    "        try:\n",
    "            content = sub_email.get_content()\n",
    "        except:\n",
    "            content = str(sub_email.get_payload())\n",
    "        if content_type == 'text/plain':\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_text(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts emails in the body to \"EMAIL\"\n",
    "import re\n",
    "def convert_email_tags(email_text):\n",
    "    return re.sub(r'([a-zA-Z0-9\\._-]+@[a-zA-Z0-9\\._-]+\\.[a-zA-Z0-9\\._-]+)',' EMAIL ',email_text,flags = re.I|re.S|re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(email_text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(email_text.strip())\n",
    "    return [i for i in words if i not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the words to get the root of words\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stemmer(email_word_list):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(w) for w in email_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "class EmailToWordCounts(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,lower_case = True, remove_email = True, remove_punctuation = True, remove_urls = True, stemming = True, remove_stopwords = True, remove_numbers = True):\n",
    "         self.lower_case =lower_case\n",
    "         self.remove_email = remove_email\n",
    "         self.remove_punctuation = remove_punctuation\n",
    "         self.remove_urls = remove_urls\n",
    "         self.stemming = stemming\n",
    "         self.remove_stopwords = remove_stopwords\n",
    "         self.remove_numbers = remove_numbers\n",
    "    def fit(self,X,y = None):\n",
    "        return self\n",
    "    def transform(self,X,y = None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.remove_urls:\n",
    "                url_extractor = urlextract.URLExtract()\n",
    "                urls = url_extractor.find_urls(text)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url,' URL ')\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'[^a-zA-Z0-9_]',' ', text, flags = re.M|re.S|re.I)\n",
    "            if self.remove_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text, flags = re.I|re.S|re.M)\n",
    "            if self.remove_email:\n",
    "                text = convert_email_tags(text)\n",
    "            if self.remove_stopwords:\n",
    "                #words without stemming\n",
    "                word_list = remove_stopwords(text)\n",
    "            if self.stemming:\n",
    "                stemmed_list = stemmer(word_list)\n",
    "            X_transformed.append(stemmed_list)\n",
    "        return X_transformed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailtowords = EmailToWordCounts()\n",
    "test = emailtowords.fit_transform(X_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "test[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'text/plain'"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "X_train[41].get_payload()[2].get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(X_train[41]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['facebook.com', 'reddit.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "import urlextract\n",
    "url_extractor = urlextract.URLExtract()\n",
    "print(url_extractor.find_urls(\"facebook.com and reddit.com and blah.come and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"I'm @ bashs & euedh leh_ss\"\n",
    "res = re.sub(r'[^a-zA-Z0-9]+',' punc ',exp,flags = re.I|re.M|re.S)\n",
    "res2 = re.sub(r'\\W+',' punc ',exp,flags = re.I|re.M|re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'I punc m punc bashs punc euedh punc leh_ss'"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_idx = [idx for idx in range(len(X_train)) if X_train[idx].get_content_type() == 'text/html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"This WEEK: Sydney Bares ALL in the park!\\nJoin her in our Live Teen Chat!\\nWatch as Sandy Strips Naked in her Dorm!\\nBest of All, see it\\n HYPERLINK\\nDon't Miss Out!\\nWatch in Awe as Stacey Suck-Starts Ken!\\nAND OUR BONUS:\\nPam & Tommy UNCUT!\\nPenthouse Forum Stories!\\nJenna Jamieson in JennaMaxx!!\\nGet in here for HYPERLINK\""
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "html_to_text(X_train[html_idx[0]].get_content()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['If',\n",
       " 'promotion',\n",
       " 'reached',\n",
       " 'error',\n",
       " 'would',\n",
       " 'prefer',\n",
       " 'receive',\n",
       " 'marketing',\n",
       " 'messages',\n",
       " 'us',\n",
       " ',',\n",
       " 'please',\n",
       " 'send',\n",
       " 'email',\n",
       " 'HYPERLINK',\n",
       " '(',\n",
       " 'one',\n",
       " 'word',\n",
       " ',',\n",
       " 'spaces',\n",
       " ')',\n",
       " 'giving',\n",
       " 'us',\n",
       " 'email',\n",
       " 'address',\n",
       " 'question',\n",
       " 'call',\n",
       " '1-888-748-7751',\n",
       " 'assistance',\n",
       " '.',\n",
       " 'Gain',\n",
       " 'access',\n",
       " 'Vast',\n",
       " 'Network',\n",
       " 'Of',\n",
       " 'Qualified',\n",
       " 'Lenders',\n",
       " 'Nationwide',\n",
       " 'Network',\n",
       " '!',\n",
       " 'This',\n",
       " 'zero-cost',\n",
       " 'service',\n",
       " 'enables',\n",
       " 'shop',\n",
       " 'mortgage',\n",
       " 'conveniently',\n",
       " 'home',\n",
       " 'computer',\n",
       " '.',\n",
       " 'Our',\n",
       " 'nationwide',\n",
       " 'database',\n",
       " 'give',\n",
       " 'access',\n",
       " 'lenders',\n",
       " 'variety',\n",
       " 'loan',\n",
       " 'programs',\n",
       " 'work',\n",
       " 'Excellent',\n",
       " ',',\n",
       " 'Good',\n",
       " ',',\n",
       " 'Fair',\n",
       " 'even',\n",
       " 'Poor',\n",
       " 'Credit',\n",
       " '!',\n",
       " 'We',\n",
       " 'choose',\n",
       " '3',\n",
       " 'mortgage',\n",
       " 'companies',\n",
       " 'database',\n",
       " 'registered',\n",
       " 'brokers/lenders',\n",
       " '.',\n",
       " 'Each',\n",
       " 'contact',\n",
       " 'offer',\n",
       " 'best',\n",
       " 'rate',\n",
       " 'terms',\n",
       " '-',\n",
       " 'charge',\n",
       " '.',\n",
       " 'You',\n",
       " 'choose',\n",
       " 'best',\n",
       " 'offer',\n",
       " 'save',\n",
       " '-',\n",
       " 'HYPERLINK',\n",
       " 'Poor',\n",
       " 'Damaged',\n",
       " 'Credit',\n",
       " 'Is',\n",
       " 'Not',\n",
       " 'A',\n",
       " 'Problem',\n",
       " '!',\n",
       " 'Consolidate',\n",
       " '&',\n",
       " 'pay',\n",
       " 'high',\n",
       " 'interest',\n",
       " 'bills',\n",
       " 'one',\n",
       " 'lower',\n",
       " 'monthly',\n",
       " 'payment',\n",
       " '!',\n",
       " 'Refinance',\n",
       " '(',\n",
       " 'without',\n",
       " 'cash',\n",
       " ')',\n",
       " 'low',\n",
       " 'FIXED',\n",
       " 'rate',\n",
       " 'payment',\n",
       " '!',\n",
       " 'Get',\n",
       " 'money',\n",
       " 'cover',\n",
       " 'expenses',\n",
       " 'tuitions',\n",
       " ',',\n",
       " 'home',\n",
       " 'improvements',\n",
       " ',',\n",
       " 'new',\n",
       " 'vehicle',\n",
       " 'vacations',\n",
       " '.',\n",
       " '-',\n",
       " 'Talk',\n",
       " 'three',\n",
       " 'lenders',\n",
       " 'today',\n",
       " '!',\n",
       " 'HYPERLINK',\n",
       " 'get',\n",
       " 'no-cost',\n",
       " 'rate',\n",
       " 'payment',\n",
       " 'quotes',\n",
       " '.',\n",
       " 'This',\n",
       " 'service',\n",
       " 'completely',\n",
       " 'FREE',\n",
       " '!',\n",
       " 'If',\n",
       " 'promotion',\n",
       " 'reached',\n",
       " 'error',\n",
       " 'want',\n",
       " 'contacted',\n",
       " 'us',\n",
       " ',',\n",
       " 'HYPERLINK',\n",
       " 'let',\n",
       " 'us',\n",
       " 'know',\n",
       " '.',\n",
       " 'You',\n",
       " 'bothered',\n",
       " 'us',\n",
       " 'email',\n",
       " 'address',\n",
       " '.',\n",
       " 'Alternatively',\n",
       " ',',\n",
       " 'may',\n",
       " 'send',\n",
       " 'email',\n",
       " 'HYPERLINK',\n",
       " 'giving',\n",
       " 'us',\n",
       " 'email',\n",
       " 'address',\n",
       " 'question',\n",
       " 'IMMEDIATE',\n",
       " 'attention',\n",
       " '.',\n",
       " 'Should',\n",
       " 'wish',\n",
       " 'delete',\n",
       " 'email',\n",
       " 'address',\n",
       " 'mailing',\n",
       " 'list',\n",
       " 'phone',\n",
       " ',',\n",
       " 'please',\n",
       " 'call',\n",
       " '1-888-748-7751',\n",
       " 'leave',\n",
       " 'email',\n",
       " 'address',\n",
       " '-',\n",
       " 'please',\n",
       " 'spell',\n",
       " 'email',\n",
       " 'address',\n",
       " 'clearly',\n",
       " '.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'also',\n",
       " 'mail',\n",
       " 'written',\n",
       " 'request',\n",
       " 'us',\n",
       " 'Compliance',\n",
       " ',',\n",
       " 'NMLN',\n",
       " ',',\n",
       " '3053',\n",
       " 'Rancho',\n",
       " 'Vista',\n",
       " 'Blvd',\n",
       " '.',\n",
       " '#',\n",
       " 'H-252',\n",
       " ',',\n",
       " 'Palmdale',\n",
       " ',',\n",
       " 'CA',\n",
       " ',',\n",
       " '93551',\n",
       " '.',\n",
       " 'Your',\n",
       " 'request',\n",
       " 'honored',\n",
       " 'within',\n",
       " '24',\n",
       " 'hours',\n",
       " 'receipt',\n",
       " 'mail',\n",
       " '.',\n",
       " 'Failure',\n",
       " 'exclude',\n",
       " 'recurring',\n",
       " 'mailer',\n",
       " 'via',\n",
       " 'lawful',\n",
       " 'channels',\n",
       " 'provided',\n",
       " 'means',\n",
       " 'given',\n",
       " 'consent',\n",
       " 'included',\n",
       " 'mailer',\n",
       " '.',\n",
       " 'You',\n",
       " 'continue',\n",
       " 'receive',\n",
       " 'email',\n",
       " 'long',\n",
       " 'NOT',\n",
       " 'delete',\n",
       " 'mailer',\n",
       " '.',\n",
       " 'Please',\n",
       " 'continue',\n",
       " 'receive',\n",
       " 'unwanted',\n",
       " 'email',\n",
       " 'provided',\n",
       " 'lawful',\n",
       " 'means',\n",
       " 'excluded',\n",
       " '.',\n",
       " 'We',\n",
       " 'log',\n",
       " ',',\n",
       " 'date',\n",
       " 'retain',\n",
       " 'ALL',\n",
       " 'delete',\n",
       " 'requests',\n",
       " '.',\n",
       " 'NO',\n",
       " 'PART',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'STATEMENT',\n",
       " 'MAY',\n",
       " 'BE',\n",
       " 'AMENDED',\n",
       " 'OR',\n",
       " 'ELIMINATED',\n",
       " '.',\n",
       " 'Thank',\n",
       " '.']"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "[w for w in word_tokenize(html_to_text(X_train[html_idx[4]].get_content()).strip()) if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}