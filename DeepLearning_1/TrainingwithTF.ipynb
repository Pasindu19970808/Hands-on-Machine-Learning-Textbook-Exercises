{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0965ba1120b0c101b3f715b6e258a73742ec1cf86f2c8b04492724c87d9f112c3",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h2> More on Tensorflow </h2> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "GPUS dramatically speed up computations by splitting computations into many smaller chunks and running them in parallel across many GPU threads. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "b = tf.Variable(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
       "array([[  1,   2,   3],\n",
       "       [  4, 100,   6]])>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "b.scatter_nd_update(indices = [[1,1]],updates = [100])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#creating a simple tensor\n",
    "t = tf.constant([[1,2,3],[4,5,6]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2, 3],\n",
       "       [5, 6]])>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#indexing\n",
    "t[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[14, 32],\n",
       "       [32, 77]])>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tf.matmul(t,tf.transpose(t))"
   ]
  },
  {
   "source": [
    "<h3> Tensors and Numpy </h3> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 5])>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=40.0>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#casting from 32bit float to a 64 bit float to sum in TF\n",
    "t2 = tf.constant(40.,dtype = tf.float64)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tf.constant(2.0) + tf.cast(t2,tf.float32)"
   ]
  },
  {
   "source": [
    "<h3> Variables in Tensorflow </h3> \n",
    "\n",
    "We cannot modify constant tensors, however we can modify tf.Variable. These are required as we need to tweak weights in a neural network. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "v = tf.Variable([[1.,2.,3.],[4.,5.,6.]])\n",
    "v"
   ]
  },
  {
   "source": [
    "A tf.Variable acts like a constant tensor and allows to perform the same operations. But it also allows you to modify th variable using the assign() method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],[4,5,6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "v.assign(2*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "v[0,1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   6.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0,0],[1,2]],updates = [100.,200.])"
   ]
  },
  {
   "source": [
    "v.scatter_nd_add(indices=[[0,0],[1,2]],updates = [100.,200.])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[200.,  42.,   6.],\n",
       "       [  8.,  10., 400.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "source": [
    "scatter methods allows you to specify the index position and add to it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3> Sparse Tensors </h3> \n",
    "\n",
    "In a Sparse Tensor, you always need to give the positions first, then the values, then the dense shape"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices = [[0,1],[1,0],[2,3]],\n",
    "                    values = [1.,2.,3.], \n",
    "                    dense_shape=[3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "source": [
    "Sparse tensors need to always be given in order of indices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 1], [0, 2]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 2., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "tf.sparse.to_dense(s5)"
   ]
  },
  {
   "source": [
    "<h3> Tensor Arrays </h3>\n",
    "\n",
    "We first crrate the tensor with a fixed size. we cannot add past this"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype = tf.float32,size = 3)\n",
    "array = array.write(0,tf.constant([1.,2.]))\n",
    "array = array.write(1,tf.constant([3.,10.]))\n",
    "array = array.write(2,tf.constant([5.,7.]))"
   ]
  },
  {
   "source": [
    "<h3> Customizing models and training algorithms </h3> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3> Custom Loss Functions </h3> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where y_true - y_pred absolute is less than 1, we want the squared loss and linear loss\n",
    "def huber_fn(y_true,y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error)/2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "\n",
    "#we need to always use tensorflow functions to be used as custom loss functions. "
   ]
  },
  {
   "source": [
    "For the next step, we just apply this to our keras model\n",
    "\n",
    "model.compile(loss = huber_fn, optimizer = \"adam\")\n",
    "\n",
    "model.fit(.....)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current implementation allows us to have one threshold of 1 in the Huber Function\n",
    "#How to change the threshold?\n",
    "def create_huber(threshold = 1.0):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_errors = tf.abs(error) <  threshold\n",
    "        #mae loss\n",
    "        squared_loss = tf.square(error)/2\n",
    "        #mse loss\n",
    "        linear_loss = threshold*tf.abs(error) - threshold**2/2\n",
    "        #if your error is less than threshold, return squared loss, \n",
    "        #else return linear_loss\n",
    "        return tf.where(is_small_errors, squared_loss,linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "source": [
    "model.compile(loss = create_huber(2.0), optimizer = \"adam\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The above causes an issue when saving the model using \n",
    "keras.callbacks.ModelCheckpoint(\"modelname.h5\", save_best_only = True)\n",
    "\n",
    "When we load the model again we will have to specify which function is being called for the loss function as the loss function is a custom one here\n",
    "\n",
    "model = keras.models.load_model(\"modelname.h5\", custom_objects = {\"huber_fn\":create_huber(2.0)})"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid the above we can inherit the Keras.losses.loss method\n",
    "\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold = 1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        #instantiate the superclass\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error)/2\n",
    "        linear_loss = self.threshold*tf.abs(error) - self.threshold**2/2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    def get_config(self):\n",
    "        #you get the base configuration of superclass\n",
    "        base_config = super().get_config()\n",
    "        #add in the threshold and creates a new dictionary to be returned\n",
    "        return {**base_config, \"threshold\":self.threshold}"
   ]
  },
  {
   "source": [
    "get_config method returns a dictionary mapping each hyperparameter name to its value. It first calls the parent class's get_config() method, then adds the new hyperparameters to this dictionary.\n",
    "\n",
    "from the above, when loading a model, we do this:\n",
    "\n",
    "**model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "custom_objects={\"HuberLoss\": HuberLoss})**\n",
    "\n",
    "Now we dont have to provide the threshold value too.\n",
    "\n",
    "When we save the mode, Keras calls the loss instance (HuberLoss) get_config() method and the returned dictionary is stored as a JSON in the h5 file. \n",
    "\n",
    "When loaded, it calls **from_config()** and creates the instance of the class, passing the return from **from_config()** to **kwargs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Custom Activation Functions, Initializers, Regularizers, and Constraints</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining custom activation functions \n",
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_glorot_initializer(shape,dtype = tf.float32):\n",
    "    stddev = tf.sqrt(2/(shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_li_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return only positive weights\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights<0, tf.zeros_like(weights),weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom regularizer using subclassing\n",
    "\n",
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self,regfactor):\n",
    "        self.factor = regfactor\n",
    "    def __call__(self,weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"regfactor\":self.factor}"
   ]
  },
  {
   "source": [
    "For losses, layers and models we implement the call() method, and for regularizers, initializers and constraints we use the _____call_____() method. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Custom Metrics </h3> \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 2., 2.],\n",
       "       [2., 2., 2.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "a = tf.Variable([[2,2,2],[2,2,2]])\n",
    "a = tf.cast(a,tf.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.11999999>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "tf.reduce_sum(tf.abs(0.01*a))"
   ]
  },
  {
   "source": [
    "At each training step the weights will be passed to the regularization function to compute the regularization loss. The return is then added to the main loss to get the final loss used for training. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3> Custom Metrics </h3> \n",
    "\n",
    "Usually metrics keep track of the mean of a metric from each epoch. \n",
    "\n",
    "Suppose we have 5 true predictions, but 4 true positives. Thats 0.8 precision. Next epoch, we have 3 true predictions with 0 true positives. Thats 0 precision, but if we use mean, it becomes 0.4 precision overall\n",
    "\n",
    "But the actual one is 8 true predictions with 4 true positives in total. Thats 0.5 precision. Hence we need an object to track the true positives and an object to track the predictions. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "source": [
    "Note above that the same precision object, under 2 runs prduces the overal precision of the data fed into it. Not a mean, or not a new precision for the the new run.\n",
    "\n",
    "This is called a streaming metric. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold = 1.0):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_errors = tf.abs(error) <  threshold\n",
    "        #mae loss\n",
    "        squared_loss = tf.square(error)/2\n",
    "        #mse loss\n",
    "        linear_loss = threshold*tf.abs(error) - threshold**2/2\n",
    "        #if your error is less than threshold, return squared loss, \n",
    "        #else return linear_loss\n",
    "        return tf.where(is_small_errors, squared_loss,linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating streaming metrics\n",
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self,threshold = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        #returns a huber function to be used in this class\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        #add weight creates variables to keep track of attributes\n",
    "        self.total = self.add_weight(\"total\",initializer= \"zeros\")\n",
    "        self.count = self.add_weight(\"count\",initializer= \"zeros\")\n",
    "    def update_state(self,y_true,y_pred,sample_weight = None):\n",
    "        result = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(result))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_pred), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total/self.count\n",
    "    def get_config(self):\n",
    "        base_config = self.get_config()\n",
    "        return {**base_config, \"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customPrecision(keras.metrics.Metric):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def update_state(self,y_true, y_pred,sample_weight = None):\n",
    "        try: \n",
    "            for _class in self.unique_classes:\n",
    "                self.total_true[_class] = self.total_true[_class] + tf.where(ytrue == _class).shape[0]\n",
    "                self.total_prediction[_class] = self.total_prediction[_class] + tf.where(ypred == _class).shape[0]\n",
    "                self.total_truepositives[_class] = self.total_truepositives[_class] + len([i for i in tf.where(ypred == _class) if i in tf.where(ytrue == _class)])\n",
    "            #return [self.total_prediction,self.total_truepositives]\n",
    "        except:\n",
    "            self.unique,_,_ = tf.unique_with_counts(ytrue)\n",
    "            #obtains the unique classes to a list that we can loop through\n",
    "            self.unique_classes = self.unique.numpy()\n",
    "            self.total_truepositives = {_class:0 for _class in self.unique_classes}\n",
    "            self.total_prediction = {_class:0 for _class in self.unique_classes}\n",
    "            self.precision_classbase = {_class:0 for _class in self.unique_classes}\n",
    "            self.total_true = {_class:0 for _class in self.unique_classes}\n",
    "            for _class in self.unique_classes:\n",
    "                self.total_true[_class] = self.total_true[_class] + tf.where(ytrue == _class).shape[0]\n",
    "                self.total_prediction[_class] = self.total_prediction[_class] + tf.where(ypred == _class).shape[0]\n",
    "                self.total_truepositives[_class] = self.total_truepositives[_class] + len([i for i in tf.where(ypred == _class) if i in tf.where(ytrue == _class)])\n",
    "            #return [self.total_prediction,self.total_truepositives]\n",
    "    def result(self):\n",
    "        for _class in self.unique_classes:\n",
    "            self.precision_classbase[_class] = self.total_truepositives[_class]/self.total_prediction[_class]\n",
    "            self.precision_classbase[_class] = self.precision_classbase[_class] * (self.total_true[_class]/sum(self.total_true.values()))\n",
    "        return sum(self.precision_classbase.values())\n",
    "    def get_config(self):\n",
    "        base_config = self.get_config()\n",
    "        return {**base_config, \"threshold\":self.threshold}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = tf.Variable([1,0,1,1,0,1,1,0,1])\n",
    "ypred = tf.Variable([1,1,0,0,1,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.48333332>"
      ]
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "prec_test = customPrecision()\n",
    "prec_test(ytrue,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: 0, 0: 0}"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "prec_test.precision_classbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.2777778>"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "hub = HuberMetric()\n",
    "hub(ytrue,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(9,) dtype=int32, numpy=array([1, 0, 1, 1, 0, 1, 1, 0, 1])>"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {0:4,1:3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 4, 1: 3}"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "sum(a.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}