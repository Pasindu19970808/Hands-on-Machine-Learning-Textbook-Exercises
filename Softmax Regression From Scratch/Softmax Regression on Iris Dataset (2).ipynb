{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Softmax Regression from Scratch on the Iris Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the entire dataset\n",
    "\n",
    "X_average = X.mean(axis = 0)\n",
    "X_std = X.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = (X - X_average)/X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been scaled. \n",
    "Now we add in a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_bias = np.c_[np.ones(shape = (len(X),1)),X_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "total_size = X_with_bias.shape[0]\n",
    "\n",
    "test_size = int(test_ratio*total_size)\n",
    "validation_size = int(validation_ratio*total_size)\n",
    "train_size = int(total_size*(1 - validation_ratio - test_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_no = np.random.permutation(total_size)\n",
    "\n",
    "test_idx = idx_no[:test_size+1]\n",
    "validation_idx = idx_no[test_size+1: test_size + validation_size + 1]\n",
    "train_idx = idx_no[test_size + validation_size + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_with_bias[train_idx]\n",
    "y_train = y[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_with_bias[validation_idx]\n",
    "y_val = y[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_with_bias[test_idx]\n",
    "y_test = y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Softmax regression, as every class will have its own set of parameters, each class will have its own one-hot-encoded column vector where 1 means the instance is of that particular class and 0 means that it belongs to a different class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_label):\n",
    "    num_classes = y_label.max() + 1\n",
    "    num_instances = len(y_label)\n",
    "    Y_one_hot = np.zeros(shape = (num_instances, num_classes))\n",
    "    Y_one_hot[np.arange(num_instances),y_label] = 1\n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one hot encoder is working now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, theta):\n",
    "    score_matrix = np.dot(X,theta) #logit\n",
    "    exp_matrix = np.exp(score_matrix)\n",
    "    exp_sum = np.sum(exp_matrix, axis = 1, keepdims = True)\n",
    "    return exp_matrix/exp_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11330361, -0.23452355, -0.20774285],\n",
       "       [ 0.43433246, -0.66647126, -0.71757054],\n",
       "       [ 1.0188498 ,  0.41245226, -0.75018439],\n",
       "       [ 0.63844637,  0.61608862,  0.53739165],\n",
       "       [ 2.16968434,  0.08167019, -0.04731371]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing theta \n",
    "n_classes = y_train.max() + 1\n",
    "n_parameters = X_with_bias.shape[1]\n",
    "theta = np.random.randn(n_parameters,n_classes)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = one_hot_encoding(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.1147066270967874\n",
      "100 1.1963805374003322\n",
      "200 0.6624494272169731\n",
      "300 0.5026173544385019\n",
      "400 0.43286463445455253\n",
      "500 0.3936400058710335\n",
      "600 0.367909231023225\n",
      "700 0.34925268284118627\n",
      "800 0.33475123171543847\n",
      "900 0.32289987267298476\n",
      "1000 0.31285004934242716\n",
      "1100 0.3040897516882617\n",
      "1200 0.2962929261084237\n",
      "1300 0.2892425059327578\n",
      "1400 0.28278843442827795\n",
      "1500 0.2768235326981102\n",
      "1600 0.2712690050779982\n",
      "1700 0.2660654044880077\n",
      "1800 0.26116681911125317\n",
      "1900 0.25653702706377907\n",
      "2000 0.25214689032529997\n",
      "2100 0.2479725500304892\n",
      "2200 0.2439941522494359\n",
      "2300 0.24019493235224745\n",
      "2400 0.23656054633924437\n",
      "2500 0.23307857516367458\n",
      "2600 0.22973815211062398\n",
      "2700 0.22652967895493362\n",
      "2800 0.22344460700990149\n",
      "2900 0.22047526618624688\n",
      "3000 0.21761472997981793\n",
      "3100 0.21485670763883996\n",
      "3200 0.2121954571050609\n",
      "3300 0.20962571399079577\n",
      "3400 0.2071426330535259\n",
      "3500 0.20474173950145896\n",
      "3600 0.20241888810291933\n",
      "3700 0.20017022854567182\n",
      "3800 0.19799217584541826\n",
      "3900 0.1958813848683037\n",
      "4000 0.1938347282335308\n",
      "4100 0.1918492770157883\n",
      "4200 0.18992228378525014\n",
      "4300 0.18805116761423593\n",
      "4400 0.18623350075074913\n",
      "4500 0.18446699671486108\n",
      "4600 0.18274949961787337\n",
      "4700 0.18107897453909455\n",
      "4800 0.1794534988229337\n",
      "4900 0.17787125418141084\n",
      "5000 0.17633051950529124\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "num_iterations = 5001\n",
    "m = len(X_train)\n",
    "eta = 0.01\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    y_probab = softmax(X_train,theta)\n",
    "    loss = -(1/m)*(np.sum(np.log(y_probab)*y_train_onehot))\n",
    "    error = y_probab - y_train_onehot \n",
    "    if iteration%100 == 0:\n",
    "        print(iteration, loss)\n",
    "    gradient = (1/m) * np.dot(np.transpose(X_train),error)\n",
    "    theta = theta - eta*gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4465294 ,  1.1398315 , -1.02226489],\n",
       "       [-1.31935586,  0.14261787,  0.22702864],\n",
       "       [ 1.5056302 , -0.44410561, -0.38040692],\n",
       "       [-1.51685068,  1.1429574 ,  2.16581991],\n",
       "       [-0.02289739, -0.33935642,  2.56629463]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.693416235970922"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(y_probab)*y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -1.62768839e+00, -1.74335684e+00,\n",
       "        -1.39706395e+00, -1.18381211e+00],\n",
       "       [ 1.00000000e+00, -1.02184904e+00, -2.43394714e+00,\n",
       "        -1.46640561e-01, -2.62386821e-01],\n",
       "       [ 1.00000000e+00, -4.16009689e-01, -1.28296331e+00,\n",
       "         1.37546573e-01,  1.32509732e-01],\n",
       "       [ 1.00000000e+00,  1.15917263e+00, -1.31979479e-01,\n",
       "         9.90107977e-01,  1.18556721e+00],\n",
       "       [ 1.00000000e+00,  1.28034050e+00,  3.28414053e-01,\n",
       "         1.10378283e+00,  1.44883158e+00],\n",
       "       [ 1.00000000e+00,  6.74501145e-01, -5.92373012e-01,\n",
       "         1.04694540e+00,  1.31719939e+00],\n",
       "       [ 1.00000000e+00, -5.37177559e-01,  1.47939788e+00,\n",
       "        -1.28338910e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.73673948e-01,  1.70959465e+00,\n",
       "        -1.16971425e+00, -1.18381211e+00],\n",
       "       [ 1.00000000e+00, -1.38535265e+00,  3.28414053e-01,\n",
       "        -1.22655167e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -5.25060772e-02, -8.22569778e-01,\n",
       "         7.62758269e-01,  9.22302838e-01],\n",
       "       [ 1.00000000e+00, -5.37177559e-01, -1.31979479e-01,\n",
       "         4.21733708e-01,  3.95774101e-01],\n",
       "       [ 1.00000000e+00,  1.15917263e+00,  3.28414053e-01,\n",
       "         1.21745768e+00,  1.44883158e+00],\n",
       "       [ 1.00000000e+00,  1.03800476e+00, -1.31979479e-01,\n",
       "         7.05920842e-01,  6.59038469e-01],\n",
       "       [ 1.00000000e+00, -5.37177559e-01,  7.88807586e-01,\n",
       "        -1.28338910e+00, -1.05217993e+00],\n",
       "       [ 1.00000000e+00,  3.10997534e-01, -5.92373012e-01,\n",
       "         5.35408562e-01,  8.77547895e-04],\n",
       "       [ 1.00000000e+00, -5.25060772e-02,  2.16998818e+00,\n",
       "        -1.45390138e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  5.53333275e-01,  5.58610819e-01,\n",
       "         5.35408562e-01,  5.27406285e-01],\n",
       "       [ 1.00000000e+00, -1.14301691e+00, -1.28296331e+00,\n",
       "         4.21733708e-01,  6.59038469e-01],\n",
       "       [ 1.00000000e+00,  6.74501145e-01,  3.28414053e-01,\n",
       "         8.76433123e-01,  1.44883158e+00],\n",
       "       [ 1.00000000e+00, -2.94841818e-01, -1.28296331e+00,\n",
       "         8.07091462e-02, -1.30754636e-01],\n",
       "       [ 1.00000000e+00, -9.00681170e-01,  5.58610819e-01,\n",
       "        -1.16971425e+00, -9.20547742e-01],\n",
       "       [ 1.00000000e+00,  1.64384411e+00,  1.24920112e+00,\n",
       "         1.33113254e+00,  1.71209594e+00],\n",
       "       [ 1.00000000e+00,  5.53333275e-01, -8.22569778e-01,\n",
       "         6.49083415e-01,  7.90670654e-01],\n",
       "       [ 1.00000000e+00, -1.14301691e+00,  1.24920112e+00,\n",
       "        -1.34022653e+00, -1.44707648e+00],\n",
       "       [ 1.00000000e+00, -1.73673948e-01, -1.28296331e+00,\n",
       "         7.05920842e-01,  1.05393502e+00],\n",
       "       [ 1.00000000e+00, -1.50652052e+00,  9.82172869e-02,\n",
       "        -1.28338910e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.74885626e+00,  3.28414053e-01,\n",
       "        -1.39706395e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -7.79513300e-01,  7.88807586e-01,\n",
       "        -1.34022653e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.26418478e+00,  7.88807586e-01,\n",
       "        -1.05603939e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.87002413e+00, -1.31979479e-01,\n",
       "        -1.51073881e+00, -1.44707648e+00],\n",
       "       [ 1.00000000e+00,  5.53333275e-01, -1.28296331e+00,\n",
       "         7.05920842e-01,  9.22302838e-01],\n",
       "       [ 1.00000000e+00, -9.00681170e-01,  7.88807586e-01,\n",
       "        -1.28338910e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -7.79513300e-01,  2.40018495e+00,\n",
       "        -1.28338910e+00, -1.44707648e+00],\n",
       "       [ 1.00000000e+00, -1.73673948e-01, -1.05276654e+00,\n",
       "        -1.46640561e-01, -2.62386821e-01],\n",
       "       [ 1.00000000e+00,  1.88617985e+00, -5.92373012e-01,\n",
       "         1.33113254e+00,  9.22302838e-01],\n",
       "       [ 1.00000000e+00,  1.03800476e+00,  9.82172869e-02,\n",
       "         1.04694540e+00,  1.58046376e+00],\n",
       "       [ 1.00000000e+00, -9.00681170e-01,  1.47939788e+00,\n",
       "        -1.28338910e+00, -1.05217993e+00],\n",
       "       [ 1.00000000e+00, -1.74885626e+00, -1.31979479e-01,\n",
       "        -1.39706395e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.50652052e+00,  3.28414053e-01,\n",
       "        -1.34022653e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.73673948e-01, -5.92373012e-01,\n",
       "         4.21733708e-01,  1.32509732e-01],\n",
       "       [ 1.00000000e+00,  5.53333275e-01, -1.28296331e+00,\n",
       "         6.49083415e-01,  3.95774101e-01],\n",
       "       [ 1.00000000e+00,  1.89829664e-01, -1.31979479e-01,\n",
       "         5.92245988e-01,  7.90670654e-01],\n",
       "       [ 1.00000000e+00,  6.86617933e-02, -1.31979479e-01,\n",
       "         7.62758269e-01,  7.90670654e-01],\n",
       "       [ 1.00000000e+00, -4.16009689e-01, -1.05276654e+00,\n",
       "         3.64896281e-01,  8.77547895e-04],\n",
       "       [ 1.00000000e+00, -9.00681170e-01, -1.28296331e+00,\n",
       "        -4.30827696e-01, -1.30754636e-01],\n",
       "       [ 1.00000000e+00,  1.28034050e+00,  9.82172869e-02,\n",
       "         7.62758269e-01,  1.44883158e+00],\n",
       "       [ 1.00000000e+00, -5.25060772e-02, -8.22569778e-01,\n",
       "         1.94384000e-01, -2.62386821e-01],\n",
       "       [ 1.00000000e+00,  7.95669016e-01, -1.31979479e-01,\n",
       "         1.16062026e+00,  1.31719939e+00],\n",
       "       [ 1.00000000e+00, -1.02184904e+00, -1.74335684e+00,\n",
       "        -2.60315415e-01, -2.62386821e-01],\n",
       "       [ 1.00000000e+00, -1.02184904e+00,  1.24920112e+00,\n",
       "        -1.34022653e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  7.95669016e-01, -5.92373012e-01,\n",
       "         4.78571135e-01,  3.95774101e-01],\n",
       "       [ 1.00000000e+00,  2.24968346e+00, -1.31979479e-01,\n",
       "         1.33113254e+00,  1.44883158e+00],\n",
       "       [ 1.00000000e+00, -5.25060772e-02, -8.22569778e-01,\n",
       "         7.62758269e-01,  9.22302838e-01],\n",
       "       [ 1.00000000e+00,  1.03800476e+00,  9.82172869e-02,\n",
       "         5.35408562e-01,  3.95774101e-01],\n",
       "       [ 1.00000000e+00, -1.02184904e+00,  3.28414053e-01,\n",
       "        -1.45390138e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -9.00681170e-01,  1.70959465e+00,\n",
       "        -1.28338910e+00, -1.18381211e+00],\n",
       "       [ 1.00000000e+00,  5.53333275e-01, -1.74335684e+00,\n",
       "         3.64896281e-01,  1.32509732e-01],\n",
       "       [ 1.00000000e+00, -2.94841818e-01, -3.62176246e-01,\n",
       "        -8.98031345e-02,  1.32509732e-01],\n",
       "       [ 1.00000000e+00,  1.89829664e-01, -1.97355361e+00,\n",
       "         7.05920842e-01,  3.95774101e-01],\n",
       "       [ 1.00000000e+00,  6.86617933e-02,  3.28414053e-01,\n",
       "         5.92245988e-01,  7.90670654e-01],\n",
       "       [ 1.00000000e+00,  1.28034050e+00,  9.82172869e-02,\n",
       "         9.33270550e-01,  1.18556721e+00],\n",
       "       [ 1.00000000e+00,  1.52267624e+00, -1.31979479e-01,\n",
       "         1.21745768e+00,  1.18556721e+00],\n",
       "       [ 1.00000000e+00, -4.16009689e-01, -1.51316008e+00,\n",
       "        -3.29657076e-02, -2.62386821e-01],\n",
       "       [ 1.00000000e+00,  3.10997534e-01, -5.92373012e-01,\n",
       "         1.37546573e-01,  1.32509732e-01],\n",
       "       [ 1.00000000e+00,  1.89829664e-01, -1.97355361e+00,\n",
       "         1.37546573e-01, -2.62386821e-01],\n",
       "       [ 1.00000000e+00, -1.26418478e+00,  7.88807586e-01,\n",
       "        -1.22655167e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.26418478e+00,  9.82172869e-02,\n",
       "        -1.22655167e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -1.02184904e+00,  7.88807586e-01,\n",
       "        -1.28338910e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  7.95669016e-01, -1.31979479e-01,\n",
       "         9.90107977e-01,  7.90670654e-01],\n",
       "       [ 1.00000000e+00, -9.00681170e-01,  1.70959465e+00,\n",
       "        -1.22655167e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  4.32165405e-01, -3.62176246e-01,\n",
       "         3.08058854e-01,  1.32509732e-01],\n",
       "       [ 1.00000000e+00,  1.64384411e+00, -1.31979479e-01,\n",
       "         1.16062026e+00,  5.27406285e-01],\n",
       "       [ 1.00000000e+00, -1.02184904e+00,  7.88807586e-01,\n",
       "        -1.22655167e+00, -1.05217993e+00],\n",
       "       [ 1.00000000e+00, -1.73673948e-01, -1.31979479e-01,\n",
       "         2.51221427e-01,  8.77547895e-04],\n",
       "       [ 1.00000000e+00,  9.16836886e-01, -1.31979479e-01,\n",
       "         3.64896281e-01,  2.64141916e-01],\n",
       "       [ 1.00000000e+00,  3.10997534e-01, -1.31979479e-01,\n",
       "         6.49083415e-01,  7.90670654e-01],\n",
       "       [ 1.00000000e+00,  1.03800476e+00, -1.31979479e-01,\n",
       "         8.19595696e-01,  1.44883158e+00],\n",
       "       [ 1.00000000e+00,  2.49201920e+00,  1.70959465e+00,\n",
       "         1.50164482e+00,  1.05393502e+00],\n",
       "       [ 1.00000000e+00, -1.74885626e+00, -3.62176246e-01,\n",
       "        -1.34022653e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  1.03800476e+00,  5.58610819e-01,\n",
       "         1.10378283e+00,  1.71209594e+00],\n",
       "       [ 1.00000000e+00, -1.14301691e+00, -1.51316008e+00,\n",
       "        -2.60315415e-01, -2.62386821e-01],\n",
       "       [ 1.00000000e+00, -9.00681170e-01,  1.01900435e+00,\n",
       "        -1.34022653e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  4.32165405e-01,  7.88807586e-01,\n",
       "         9.33270550e-01,  1.44883158e+00],\n",
       "       [ 1.00000000e+00, -6.58345429e-01,  1.47939788e+00,\n",
       "        -1.28338910e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00, -5.37177559e-01,  7.88807586e-01,\n",
       "        -1.16971425e+00, -1.31544430e+00],\n",
       "       [ 1.00000000e+00,  1.89829664e-01, -8.22569778e-01,\n",
       "         7.62758269e-01,  5.27406285e-01],\n",
       "       [ 1.00000000e+00, -1.73673948e-01,  3.09077525e+00,\n",
       "        -1.28338910e+00, -1.05217993e+00],\n",
       "       [ 1.00000000e+00,  6.74501145e-01, -8.22569778e-01,\n",
       "         8.76433123e-01,  9.22302838e-01],\n",
       "       [ 1.00000000e+00, -2.94841818e-01, -8.22569778e-01,\n",
       "         2.51221427e-01,  1.32509732e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4465294 ,  1.1398315 , -1.02226489],\n",
       "       [-1.31935586,  0.14261787,  0.22702864],\n",
       "       [ 1.5056302 , -0.44410561, -0.38040692],\n",
       "       [-1.51685068,  1.1429574 ,  2.16581991],\n",
       "       [-0.02289739, -0.33935642,  2.56629463]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_res1 = theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions using the Softmax Regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 1, 2, 0, 0,\n",
       "       1, 1, 2, 0, 0, 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_val = softmax(X_val,theta_res1)\n",
    "results_val = np.argmax(score_val, axis = 1)\n",
    "results_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0,\n",
       "       1, 1, 2, 0, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  7,  0],\n",
       "       [ 0,  2, 11]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val,results_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_val,results_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27467813,  0.55411656,  0.91351585],\n",
       "       [ 1.36483412, -1.96477116, -1.10033411],\n",
       "       [-1.73220624, -0.73448618,  0.47006739],\n",
       "       [-0.08639488, -0.32797291,  0.95578971],\n",
       "       [-0.18387189, -1.49720363,  0.65035392]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = y_train.max() + 1\n",
    "n_parameters = X_with_bias.shape[1]\n",
    "theta_with_reg = np.random.randn(n_parameters,n_classes)\n",
    "theta_with_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2562446607869413\n",
      "100 0.31592464350595484\n",
      "200 0.2624762350691646\n",
      "300 0.23015232317993664\n",
      "400 0.20778162216172663\n",
      "500 0.1914637460193028\n",
      "600 0.17914010618145662\n",
      "700 0.16957687580676903\n",
      "800 0.16198764057115825\n",
      "900 0.15585015754059867\n",
      "1000 0.15080618361220224\n",
      "1100 0.14660311703009019\n",
      "1200 0.1430585129150659\n",
      "1300 0.14003776986119498\n",
      "1400 0.1374396909349138\n",
      "1500 0.13518690015823842\n",
      "1600 0.13321933480290893\n",
      "1700 0.13148973387274335\n",
      "1800 0.12996045094549785\n",
      "1900 0.12860116353555345\n",
      "2000 0.1273872006828902\n",
      "2100 0.12629830417658255\n",
      "2200 0.1253176987432234\n",
      "2300 0.12443138558164397\n",
      "2400 0.12362759952569875\n",
      "2500 0.12289638757851448\n",
      "2600 0.12222927851479658\n",
      "2700 0.12161902154746146\n",
      "2800 0.12105937789480728\n",
      "2900 0.12054495324500954\n",
      "3000 0.12007106211355348\n",
      "3100 0.11963361727438916\n",
      "3200 0.11922903905427573\n",
      "3300 0.1188541804755061\n",
      "3400 0.11850626512908\n",
      "3500 0.11818283533887332\n",
      "3600 0.117881708694779\n",
      "3700 0.11760094143040917\n",
      "3800 0.11733879742871198\n",
      "3900 0.11709372187869632\n",
      "4000 0.11686431879459075\n",
      "4100 0.11664933175723846\n",
      "4200 0.11644762735540176\n",
      "4300 0.1162581808987455\n",
      "4400 0.11608006404978621\n",
      "4500 0.11591243408300797\n",
      "4600 0.11575452452871975\n",
      "4700 0.11560563699943432\n",
      "4800 0.11546513402943354\n",
      "4900 0.1153324327851955\n",
      "5000 0.11520699952663713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00880104,  3.563133  , -2.37897977],\n",
       "       [-1.38007534,  0.32733129,  0.08341771],\n",
       "       [ 1.13394694, -0.5921483 , -1.68007663],\n",
       "       [-3.08432686,  0.18487337,  3.20811869],\n",
       "       [-2.92997921, -1.79587191,  4.13823567]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "num_iterations = 5001\n",
    "m = len(X_train)\n",
    "eta = 0.1\n",
    "epsilon = 1e-07\n",
    "alpha = 0.1 #regularization \n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    y_probab = softmax(X_train,theta_with_reg)\n",
    "    cost_func = -(1/m)*(np.sum(np.log(y_probab)*y_train_onehot)) \n",
    "    reg_loss = (1/(2*m))*np.sum(np.square(theta_with_reg[1:]))\n",
    "    loss = cost_func + (alpha * reg_loss)\n",
    "    error = y_probab - y_train_onehot \n",
    "    if iteration%100 == 0:\n",
    "        print(iteration, loss)\n",
    "    cost_gradient = (1/m) * np.dot(np.transpose(X_train),error) \n",
    "    reg_gradient = (alpha/m) * np.vstack((np.zeros(shape = (1,n_classes)),theta_with_reg[1:]))\n",
    "    gradient = cost_gradient + reg_gradient\n",
    "    theta_with_reg = theta_with_reg - eta*gradient\n",
    "\n",
    "theta_with_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 2, 2, 1, 2, 0, 0,\n",
       "       1, 1, 2, 0, 0, 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_val = softmax(X_val,theta_with_reg)\n",
    "results_val_reg = np.argmax(score_val, axis = 1)\n",
    "results_val_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  7,  0],\n",
       "       [ 0,  2, 11]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, results_val_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [-0.18977723,  0.07635881,  0.05053192],\n",
       "       [ 0.197505  , -0.00872053, -0.11656378],\n",
       "       [-0.29995985, -0.00420465,  0.30556469],\n",
       "       [-0.19439606, -0.12811991,  0.45659941]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[np.zeros([1, n_classes]), alpha * theta_with_reg[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [-0.18977723,  0.07635881,  0.05053192],\n",
       "       [ 0.197505  , -0.00872053, -0.11656378],\n",
       "       [-0.29995985, -0.00420465,  0.30556469],\n",
       "       [-0.19439606, -0.12811991,  0.45659941]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha*np.vstack((np.zeros(shape = (1,n_classes)),theta_with_reg[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax Regression with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val\n",
    "\n",
    "no_classes = np.max(y_val) + 1\n",
    "no_instances = y_val.shape[0]\n",
    "\n",
    "y_val_onehot = np.zeros(shape = (no_instances, no_classes))\n",
    "y_val_onehot[np.arange(no_instances),y_val] = 1\n",
    "y_val_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0,\n",
       "       1, 1, 2, 0, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_early = np.random.randn(n_parameters,n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09137964857719465\n",
      "500 0.09785357798534092\n",
      "1000 0.10367444883927036\n",
      "1388 0.06788885940353104\n",
      "1389 0.06788886583032315 Early Stop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.55111335,  2.54133878, -1.27174439],\n",
       "       [-1.73123914,  0.73574931,  0.44353022],\n",
       "       [ 1.45805029, -0.48546951, -0.87369695],\n",
       "       [-3.51336959, -0.19333641,  2.33333496],\n",
       "       [-1.06606508, -1.58209491,  2.17680252]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 5001\n",
    "m = len(X_train)\n",
    "alpha = 0.1\n",
    "best_loss = np.infty\n",
    "\n",
    "\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    y_probab = softmax(X_train,theta_early)\n",
    "    cost_loss = (-1/m) * np.sum(np.log(y_probab)*y_train_onehot)\n",
    "    reg_loss = (alpha/(2*m)) * np.sum(np.square(theta_early))\n",
    "    loss = cost_func + reg_loss\n",
    "    error = y_probab - y_train_onehot\n",
    "    cost_grad = (1/m)*np.dot(np.transpose(X_train),error)\n",
    "    reg_grad = (alpha/m)*np.vstack((np.zeros(shape = (1,n_classes)),theta_with_reg[1:]))\n",
    "    gradient = cost_grad + reg_grad\n",
    "    theta_early = theta_early - eta*gradient\n",
    "    \n",
    "    \n",
    "    y_probab_val = softmax(X_val,theta_early)\n",
    "    cost_loss_val = (-1/m) * np.sum(np.log(y_probab_val)*y_val_onehot)\n",
    "    reg_loss_val = (alpha/(2*m)) * np.sum(np.square(theta_early))\n",
    "    loss_val = cost_loss_val + reg_loss_val\n",
    "    if iteration%500 == 0:\n",
    "        print(iteration,loss)\n",
    "    if loss_val < best_loss:\n",
    "        best_loss = loss_val\n",
    "    else:\n",
    "        print(iteration - 1, best_loss)\n",
    "        print(iteration, loss_val, 'Early Stop')\n",
    "        break\n",
    "\n",
    "theta_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 1, 2, 0, 0,\n",
       "       1, 1, 2, 0, 0, 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_val = softmax(X_val,theta_early)\n",
    "results_val_reg = np.argmax(score_val, axis = 1)\n",
    "results_val_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  7,  0],\n",
       "       [ 0,  1, 12]], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, results_val_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
